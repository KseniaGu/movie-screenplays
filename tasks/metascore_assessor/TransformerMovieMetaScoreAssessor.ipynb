{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransformerMovieMetaScoreAssessor.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "8uQqkmnezcZ9",
        "WEI47aQq7qhO",
        "PcugufEO7_4d",
        "e-et7ioyS9Ci"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiFfXLMU9joH"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOjKisXazFam"
      },
      "source": [
        "!pip install stanza"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d56TcrF5KjkM"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install mlflow --quiet\n",
        "!pip install pyngrok --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI3h-Gl1rZ5x"
      },
      "source": [
        "import os \n",
        "import torch \n",
        "#import stanza\n",
        "import pickle \n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "import seaborn as sn\n",
        "from matplotlib import pyplot as plt \n",
        "import numpy as np \n",
        "import datetime\n",
        "import random \n",
        "from shutil import copytree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, LongformerTokenizer, \\\n",
        "    LongformerForSequenceClassification, BertForSequenceClassification, AdamW,\\\n",
        "    get_cosine_schedule_with_warmup, BertTokenizerFast, BertModel\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "from torch.nn import CrossEntropyLoss, LSTM\n",
        "import torch\n",
        "from sklearn.metrics import max_error, balanced_accuracy_score\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torch.optim as Opt\n",
        "#torch.set_default_tensor_type(torch.HalfTensor)\n",
        "#torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
        "import mlflow\n",
        "from pyngrok import ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uQqkmnezcZ9"
      },
      "source": [
        "## Lemmatization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHv-oPXa3Ryj"
      },
      "source": [
        "stanza.download('en')\n",
        "nlp = stanza.Pipeline(lang='en', processors='tokenize, lemma')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur8kPMvk3TnR"
      },
      "source": [
        "# 2347/2858 \n",
        "for file_name in tqdm(os.listdir(config['paths']['scripts'])):\n",
        "    imdb_id = file_name.split('_')[1].replace('.txt', '')\n",
        "    if not os.path.exists(os.path.join(config['paths']['script_lemmas'], file_name.replace('.txt','_lemmas.txt'))):\n",
        "        text = read_script(os.path.join(config['paths']['scripts'], file_name))\n",
        "        try:\n",
        "            doc = nlp(text)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            continue\n",
        "        doc_sentences = []\n",
        "        for sentence in doc.sentences:\n",
        "            doc_sentences.append(' '.join([word.lemma for word in sentence.words]))    \n",
        "        processed_text = ' '.join(doc_sentences)\n",
        "        with open(os.path.join(config['paths']['script_lemmas'], file_name.replace('.txt','_lemmas.txt')), 'w', encoding='utf-8') as f:\n",
        "                f.write(processed_text)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb4TvB5Gukik"
      },
      "source": [
        "print(len(os.listdir(config['paths']['script_lemmas'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3RMxrEvzeoy"
      },
      "source": [
        "def process_with_stanza(imdb_id_to_texts, lang='en', processors='tokenize, lemma'):\n",
        "    '''\n",
        "    Args:\n",
        "        reviews (list of str): raw reviews\n",
        "        lang (str): language\n",
        "        processors (str): preprocessing functions\n",
        "    '''\n",
        "    stanza.download('en')\n",
        "    nlp = stanza.Pipeline(lang=lang, processors=processors)\n",
        "    #processed_texts = read_processed_texts()\n",
        "    processed_texts = {}\n",
        "    \n",
        "    for imdb_id, text in tqdm(imdb_id_to_texts.items()):\n",
        "        try:\n",
        "            doc = nlp(text)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            continue\n",
        "        doc_sentences = []\n",
        "\n",
        "        for sentence in doc.sentences:\n",
        "            doc_sentences.append(' '.join([word.lemma for word in sentence.words]))\n",
        "            \n",
        "        processed_texts[imdb_id] = ' '.join(doc_sentences)\n",
        "        #processed_texts.append(' '.join(doc_sentences))\n",
        "    with open(os.path.join(config['paths']['script_lemmas'], , 'wb') as f:\n",
        "        pickle.dump(processed_texts, f)\n",
        "\n",
        "    return processed_reviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXNzbjif6Txj"
      },
      "source": [
        "# Regression (bert-based):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uiKJStaC9aB"
      },
      "source": [
        "## initialize model object and print this object to see the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9VQllQQr9A1"
      },
      "source": [
        "config = { \n",
        "        'paths':\n",
        "         { \n",
        "            'scripts' : '/content/drive/MyDrive/NLP/Movie scripts dataset/Movie scripts and annotations/Scripts',\n",
        "            'movies_matching_scores' : '/content/drive/MyDrive/NLP/Movie scripts dataset/Movie characters/Matching evaluation and statistics/movies_mean_matching_scores.xlsx',\n",
        "            'logs_dir':'/content/drive/MyDrive/NLP/Movie scripts models/BERTScorer/logs',\n",
        "            'ckpt_dir': '/content/drive/MyDrive/NLP/Movie scripts models/BERTScorer/ckpts',\n",
        "            'script_annotations': '/content/drive/MyDrive/NLP/Movie scripts dataset/Movie scripts and annotations/Script annotations by BERT/row_classification',\n",
        "            #'manual_annotations': '/content/drive/MyDrive/NLP/Movie scripts dataset/Movie scripts and annotations/Script manual annotations',\n",
        "             'mlruns': '/content/drive/MyDrive/NLP/Movie scripts models/BERTScorer/mlruns',\n",
        "             'movie_meta_data': '/content/drive/MyDrive/NLP/Movie scripts dataset/Movie meta data/movie_meta_data.csv',\n",
        "             'script_lemmas':'/content/drive/MyDrive/NLP/Movie scripts dataset/Movie scripts and annotations/Scripts_lemmas',\n",
        "             'meta_score_exampels': '/content/drive/MyDrive/NLP/Movie scripts dataset/Baseline models/MetaScoreAssessorExamples'\n",
        "        },\n",
        "        'train': {\n",
        "                'optim' : {\n",
        "                    'AdamW':{\n",
        "                        'lr':1e-4#,\n",
        "                        #'eps': 1e-8,\n",
        "                        #'weight_decay':0.0001\n",
        "                    }\n",
        "                },\n",
        "                #'grad_accum_iters': 2, \n",
        "                'embedding_size': 768, \n",
        "                'model': BertForSequenceClassification, # from [BertForSequenceClassification, LongformerForSequenceClassification]\n",
        "                'tokenizer':BertTokenizerFast, # from [BertTokenizer, LongformerTokenizer]\n",
        "                'pretrained_model_type': 'bert-base-cased', # from ['bert-base-cased', 'allenai/longformer-base-4096']\n",
        "                 'scene_as_chunk': True, \n",
        "                #'max_script_length': 65540 , #  131072, 65540, 32770\n",
        "                'max_seq_length': 512,\n",
        "                'max_scene_number' : 100, \n",
        "                'num_classes' : 1,\n",
        "                'nrof_steps' : 1000, \n",
        "                'nrof_epochs' : 200, \n",
        "                'tr_batch_size' : 4,\n",
        "                'tst_batch_size' : 4,\n",
        "                'exp_name':'script_scorer', \n",
        "                'device': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "                'load_model':True, \n",
        "                'save_model':True \n",
        "                }\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E1NttXl_h0d"
      },
      "source": [
        "tokenizer = config['train']['tokenizer'].from_pretrained(config['train']['pretrained_model_type'], \n",
        "                                          do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_MvUq24rc8c"
      },
      "source": [
        "## Dataset preprocessing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEI47aQq7qhO"
      },
      "source": [
        "### structures:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULIu2ojM3DgD"
      },
      "source": [
        "def read_script(path):\n",
        "    try:\n",
        "        with open(path, 'r') as f:\n",
        "            text = f.read()\n",
        "            \n",
        "    except:\n",
        "        with open(path, 'r', encoding='latin-1') as f:\n",
        "            text = f.read()\n",
        "\n",
        "    return text \n",
        "\n",
        "def show_histogram(x_data, y_data, values_to_show=None, figsize=(40, 10), x_label='x', y_label='y',\n",
        "                   set_rotation=False, title='title', file_path='name.png', dpi=100, to_save=False, to_show=True):\n",
        "\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    h = sns.barplot(x=x_data, y=y_data, palette=\"Blues_d\")\n",
        "    if values_to_show:\n",
        "        for i,y in enumerate(y_data):\n",
        "            h.text(i, y, str(y)+'\\n('+str(values_to_show[i]) + ')', color='black', ha='center')\n",
        "    if set_rotation:\n",
        "        h.set_xticklabels(h.get_xticklabels(), rotation=45)\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.title(title)\n",
        "    if to_show:\n",
        "        plt.show()\n",
        "\n",
        "    if to_save:\n",
        "        fig.savefig(file_path, dpi=dpi, bbox_inches='tight')\n",
        "\n",
        "def remove_labels(row):\n",
        "    if row.startswith('text:'):\n",
        "        row = row[6:]\n",
        "    elif row.startswith('dialog:'):\n",
        "        row = row[8:]\n",
        "    elif row.startswith('speaker_heading:'):\n",
        "        row = row[17:]\n",
        "    elif row.startswith('scene_heading:'):\n",
        "        row = row[15:]\n",
        "    return row.strip()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG_WrVq-rhlA"
      },
      "source": [
        "class ScriptData:\n",
        "    def __init__(self, config, tokenizer):\n",
        "        self.config = config \n",
        "        self.tokenizer = tokenizer\n",
        "        self.movie_meta_dict = self.read_movie_meta_data()\n",
        "        self.scripts, self.labels, self.imdb_ids = self._get_scripts_and_labels(to_load=True)\n",
        "        self.scripts_scenes = self.get_script_scenes()\n",
        "    \n",
        "    def read_movie_meta_data(self):\n",
        "        movie_meta_df = pd.read_csv(self.config['paths']['movie_meta_data'])\n",
        "        movie_meta_dict = dict(zip(movie_meta_df['imdbid'].tolist(), \n",
        "                                   movie_meta_df['metascore'].tolist()))\n",
        "        \n",
        "        return movie_meta_dict\n",
        "    \n",
        "\n",
        "    def _get_scripts_and_labels(self, to_load=False, from_anno=False):\n",
        "        if not (to_load and os.path.exists('scripts.pickle') and os.path.exists('labels.pickle')):\n",
        "            scripts, labels, imdb_ids = [], [], []\n",
        "            script_iterator_files = self.config['paths']['script_annotations'] if self.config['train']['scene_as_chunk'] else self.config['paths']['scripts']\n",
        "            #for file_name in tqdm(os.listdir(self.config['paths']['scripts'])):\n",
        "            for file_name in tqdm(os.listdir(script_iterator_files)):\n",
        "                imdb_id = file_name.split('_')[1].replace('.txt', '')\n",
        "                if int(imdb_id) in self.movie_meta_dict:\n",
        "                    if self.movie_meta_dict[int(imdb_id)]!=-1:\n",
        "                        with open(os.path.join(script_iterator_files, file_name), 'r') as f:\n",
        "                            anno_lines = f.readlines()\n",
        "                        #text = read_script(os.path.join(self.config['paths']['scripts'], file_name))\n",
        "                        scripts.append(anno_lines)\n",
        "                        labels.append(float(self.movie_meta_dict[int(imdb_id)]) / 100.)\n",
        "                        imdb_ids.append(imdb_id)\n",
        "                        #labels.append(int(self.movie_meta_dict[int(imdb_id)]>=60))\n",
        "            with open('scripts.pickle', 'wb') as f:\n",
        "                pickle.dump(scripts, f)\n",
        "            with open('labels.pickle', 'wb') as f:\n",
        "                pickle.dump(labels, f)\n",
        "            with open('imdb_ids.pickle', 'wb') as f:\n",
        "                pickle.dump(imdb_ids, f)\n",
        "            print('Data saved')\n",
        "        else:\n",
        "            with open('scripts.pickle', 'rb') as f:\n",
        "                scripts = pickle.load(f)\n",
        "            with open('labels.pickle', 'rb') as f:\n",
        "                labels = pickle.load(f)\n",
        "            with open('imdb_ids.pickle', 'rb') as f:\n",
        "                imdb_ids = pickle.load(f)\n",
        "            print('Data loaded')\n",
        "        \n",
        "        return scripts, labels, imdb_ids\n",
        "    \n",
        "    '''\n",
        "    def tokenize_scripts(self, to_load=True):\n",
        "        if to_load and os.path.exists('tokenized_scripts.pickle'):\n",
        "            with open('tokenized_scripts.pickle', 'rb') as f:\n",
        "                tokenized_scripts = pickle.load(f)\n",
        "        else:\n",
        "            tokenized_scripts = self.tokenizer(self.scripts)['input_ids']\n",
        "            tokenized_scripts = [x[1:] for x in tokenized_scripts] # remove cls \n",
        "            with open('tokenized_scripts.pickle', 'wb') as f:\n",
        "                pickle.dump(tokenized_scripts, f)\n",
        "        return tokenized_scripts\n",
        "    '''\n",
        "    def prepare_tokenized_chunks_masks_labels(self, \n",
        "                                              tokenized_script_chunks, \n",
        "                                              attention_masks,\n",
        "                                              labels):\n",
        "        tokenized_script_chunks = [torch.tensor(chunk) for chunk in tokenized_script_chunks]\n",
        "        attention_masks = [torch.tensor(mask) for mask in attention_masks]\n",
        "        padded_tokenized_script_chunks = pad_sequence(tokenized_script_chunks, \n",
        "                                                      padding_value=0, batch_first=True)# for BERT pad = 0 ?\n",
        "        padded_attention_masks = pad_sequence(attention_masks, \n",
        "                                              padding_value=0, batch_first=True)\n",
        "        labels = torch.tensor(labels, dtype=torch.float)\n",
        "        #labels = torch.LongTensor(labels)\n",
        "\n",
        "        return padded_tokenized_script_chunks, padded_attention_masks, labels\n",
        "\n",
        "    def get_script_scenes(self):\n",
        "        scripts_scenes = []\n",
        "\n",
        "        scene_text = ''\n",
        "        for i, script_lines in enumerate(self.scripts):\n",
        "            scripts_scenes.append([])\n",
        "            for line_num, line in enumerate(script_lines):\n",
        "                if line.startswith('scene_heading:'):\n",
        "                    if scene_text:\n",
        "                        scripts_scenes[-1].append(scene_text)\n",
        "                    scene_text = remove_labels(line)\n",
        "                else:\n",
        "                    scene_text+=remove_labels(line)\n",
        "            if not scripts_scenes[-1]:\n",
        "                scripts_scenes.pop(-1)\n",
        "                self.labels.pop(i)\n",
        "                self.imdb_ids.pop(i)\n",
        "\n",
        "        return scripts_scenes\n",
        "\n",
        "    def make_tokenized_chunks_for_scripts(self, to_load=True):\n",
        "        if not (to_load and os.path.exists('tokenized_script_chunks.pickle') and os.path.exists('attention_masks.pickle')):\n",
        "            tokenized_script_chunks, attention_masks = [], []\n",
        "            text_iterator = self.scripts_scenes if self.config['train']['scene_as_chunk'] else self.scripts \n",
        "\n",
        "            for script_scenes in tqdm(text_iterator):\n",
        "                if len(script_scenes)>0:\n",
        "                    tokenized_scenes = self.tokenizer(script_scenes, truncation=True, \n",
        "                                                    padding='max_length',\n",
        "                                                    return_attention_mask=True) #['input_ids']\n",
        "                    tokenized_scenes_ids = tokenized_scenes['input_ids'][:self.config['train']['max_scene_number']]\n",
        "                    tokenized_scenes_attention_masks = tokenized_scenes['attention_mask'][:self.config['train']['max_scene_number']]\n",
        "                    tokenized_script_chunks.append(tokenized_scenes_ids)\n",
        "                    attention_masks.append(tokenized_scenes_attention_masks)\n",
        "            with open('tokenized_script_chunks.pickle', 'wb') as f:\n",
        "                pickle.dump(tokenized_script_chunks, f)\n",
        "            with open('attention_masks.pickle', 'wb') as f:\n",
        "                pickle.dump(attention_masks, f)\n",
        "        else:\n",
        "            with open('tokenized_script_chunks.pickle', 'rb') as f:\n",
        "                tokenized_script_chunks = pickle.load(f)\n",
        "            with open('attention_masks.pickle', 'rb') as f:\n",
        "                attention_masks = pickle.load(f)\n",
        "                \n",
        "        return tokenized_script_chunks, attention_masks\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    def make_tokenized_chunks_for_scripts(self, to_load=False):\n",
        "        tokenized_scripts = self.tokenize_scripts()\n",
        "        tokenized_script_chunks, attention_masks = [], []\n",
        "        max_script_l = self.config['train']['max_script_length']\n",
        "        max_seq_l = self.config['train']['max_seq_length']\n",
        "        n = int(max_script_l / (max_seq_l//2)) - 1\n",
        "        \n",
        "        for t_script in tqdm(tokenized_scripts):    \n",
        "            t_script = t_script[:max_script_l]\n",
        "            n = int(len(t_script) / (max_seq_l))\n",
        "            script_chunks_masks = [(t_script[i*(max_seq_l):i*(max_seq_l) + max_seq_l - 1], [1]*(min(max_seq_l, len(t_script) - i*(max_seq_l - 1)))) for i in range(n)]\n",
        "\n",
        "            if len(script_chunks_masks[-1][0]) < max_seq_l - 1 :\n",
        "                script_chunks_masks[-1] = (script_chunks_masks[-1][0] + [1] * (max_seq_l - 1 - len(script_chunks_masks[-1][0])),\n",
        "                                           script_chunks_masks[-1][1] + [0] * (max_seq_l - 1 - len(script_chunks_masks[-1][1])))\n",
        "            \n",
        "            script_chunks, script_masks = zip(*script_chunks_masks)\n",
        "            script_chunks = [[101] + x for x in script_chunks]\n",
        "            text_masks = [[1] + x for x in text_masks]\n",
        "            tokenized_script_chunks.append(script_chunks)\n",
        "            attention_masks.append(script_masks)\n",
        "\n",
        "        return tokenized_scripts, tokenized_script_chunks, attention_masks\n",
        "    '''\n",
        "    def get_train_val_split(self):\n",
        "        #_, tokenized_script_chunks, attention_masks = self.make_tokenized_chunks_for_scripts()\n",
        "        tokenized_script_chunks, attention_masks = self.make_tokenized_chunks_for_scripts()\n",
        "        \n",
        "        tr_inputs, val_inputs, tr_masks, val_masks, tr_labels, val_labels, tr_imdb_ids, val_imdb_ids = train_test_split(\n",
        "            tokenized_script_chunks, attention_masks,  \n",
        "            self.labels, self.imdb_ids, \n",
        "             test_size=0.2, random_state=11)\n",
        "        tst_inputs, val_inputs, tst_masks, val_masks, tst_labels, val_labels, tst_imdb_ids, val_imdb_ids = train_test_split(\n",
        "            val_inputs, val_masks, val_labels, val_imdb_ids, \n",
        "            test_size=0.25, random_state=11)\n",
        "        classes_info = 'Train set: '+str(len(tr_inputs))+'\\nVal set: ' + str(len(val_inputs)) +'\\nTest set: '+str(len(tst_inputs))\n",
        "        with open('dataset_info.txt', 'w') as f:\n",
        "            f.write(classes_info)\n",
        "        mlflow.log_artifact('dataset_info.txt')\n",
        "\n",
        "        tr_inputs, tr_masks, tr_labels = self.prepare_tokenized_chunks_masks_labels(\n",
        "            tr_inputs, tr_masks, tr_labels)\n",
        "        val_inputs, val_masks, val_labels = self.prepare_tokenized_chunks_masks_labels(\n",
        "            val_inputs, val_masks, val_labels)\n",
        "        tst_inputs, tst_masks, tst_labels = self.prepare_tokenized_chunks_masks_labels(\n",
        "            tst_inputs, tst_masks, tst_labels)\n",
        "        \n",
        "        return tr_inputs, tr_masks, tr_labels, tr_imdb_ids, val_inputs, val_masks, val_labels, val_imdb_ids, tst_inputs, tst_masks, tst_labels, tst_imdb_ids\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1tySQRSaYUe"
      },
      "source": [
        "def get_dataloader(input_ids, labels, attention_masks, batch_size=1,  \n",
        "                   phase='train', sampler=None):\n",
        "        dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "        if phase=='train':\n",
        "            sampler = sampler if not sampler is None else RandomSampler(dataset)\n",
        "            dataloader = DataLoader(\n",
        "                        dataset,  \n",
        "                        batch_size = batch_size,\n",
        "                        sampler = sampler,\n",
        "                        drop_last = True\n",
        "                    )\n",
        "        else:\n",
        "            dataloader = DataLoader(\n",
        "                        dataset,  \n",
        "                        batch_size = batch_size,\n",
        "                        drop_last = True\n",
        "                    )\n",
        "\n",
        "        return dataloader "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCnARWcEaaEr"
      },
      "source": [
        "def get_data_loaders():\n",
        "    SD = ScriptData(config, tokenizer)\n",
        "    #tr_inputs, val_inputs, tst_inputs, tr_labels, val_labels, tst_labels = AD.get_train_val_split()\n",
        "    #tr_inputs, tr_attention_masks, tr_labels, val_inputs, val_attention_masks, \\\n",
        "    #val_labels, tst_inputs, tst_attention_masks, tst_labels =SD.get_train_val_split()\n",
        "    tr_inputs, tr_attention_masks, tr_labels, tr_imdb_ids, val_inputs, val_attention_masks, val_labels, val_imdb_ids, tst_inputs, tst_attention_masks, tst_labels, tst_imdb_ids =  SD.get_train_val_split()\n",
        "\n",
        "    #tr_loader = get_dataloader(tr_inputs[[1,2,9,19]], tr_labels[[1,2,9,19]],  tr_attention_masks[[1,2,9,19]],\n",
        "    tr_loader = get_dataloader(tr_inputs, tr_labels,  tr_attention_masks,\n",
        "                            batch_size=config['train']['tr_batch_size'])\n",
        "    val_loader = get_dataloader(val_inputs, val_labels,  val_attention_masks,\n",
        "                                batch_size=config['train']['tst_batch_size'])\n",
        "    tst_loader = get_dataloader(tst_inputs, tst_labels,  tst_attention_masks,\n",
        "                                batch_size=config['train']['tst_batch_size'])\n",
        "    \n",
        "    return tr_loader, val_loader, tst_loader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcugufEO7_4d"
      },
      "source": [
        "### Check:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrEp7xPV7RwR"
      },
      "source": [
        "SD = ScriptData(config, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZnNz_4x5K5n"
      },
      "source": [
        "print(SD.imdb_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XCKfSawYSGw"
      },
      "source": [
        "print(SD.labels[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERXFy1AyCM3J"
      },
      "source": [
        "tokenized_scripts, tokenized_chunks_for_scripts, attention_masks = SD.make_tokenized_chunks_for_scripts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rweow8E96VM"
      },
      "source": [
        "#tr_inputs, tr_masks, tr_labels, val_inputs, val_masks, val_labels, tst_inputs, tst_masks, tst_labels = SD.get_train_val_split()\n",
        "tr_inputs, tr_masks, tr_labels, tr_imdb_ids, val_inputs, val_masks, val_labels, val_imdb_ids, tst_inputs, tst_masks, tst_labels, tst_imdb_ids = SD.get_train_val_split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JAyZ8CK8fXS"
      },
      "source": [
        "print(len(tr_imdb_ids))\n",
        "print(len(tr_inputs))\n",
        "print(len(val_imdb_ids))\n",
        "print(len(val_inputs))\n",
        "print(len(tst_imdb_ids))\n",
        "print(len(tst_inputs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB0rn0_i8iM0"
      },
      "source": [
        "print(tr_imdb_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPRoo9jeBFqR"
      },
      "source": [
        "print(min(tr_inds))\n",
        "print(max(tr_inds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YKHLkFWDI8F"
      },
      "source": [
        "print(min(val_inds))\n",
        "print(max(val_inds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjIYkvv-BJlc"
      },
      "source": [
        "print(min(tst_inds))\n",
        "print(max(tst_inds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Hzu8Zf8LGJ"
      },
      "source": [
        "imdb_ids_to_labels = {'tr': dict(zip(tr_imdb_ids, tr_labels)), 'val':dict(zip(val_imdb_ids, val_labels)), 'tst':dict(zip(tst_imdb_ids, tst_labels))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Geap4tAB8iIv"
      },
      "source": [
        "print(imdb_ids_to_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kchhB7-h8r_k"
      },
      "source": [
        "print(imdb_ids_to_labels['tr']['0086423'].item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4waxmpj_kh-"
      },
      "source": [
        "examples_inds = {'train':tr_inds, 'val':val_inds, 'test':tst_inds}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvxCV7KpDMy5"
      },
      "source": [
        "with open('meta_score_data_inds.pickle', 'wb') as f:\n",
        "    pickle.dump(examples_inds, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiAxdlswVSV7"
      },
      "source": [
        "print(tr_labels[:20])\n",
        "print(tr_labels[[1,2,9,19]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIz2C7YsGCzA"
      },
      "source": [
        "tr_loader, val_loader, tst_loader = get_data_loaders()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfPS8epQ2Y-w"
      },
      "source": [
        "for d in tr_loader:\n",
        "    print(d)\n",
        "    print(d[0].shape)\n",
        "    print(d[1].shape)\n",
        "    print(d[2].shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-et7ioyS9Ci"
      },
      "source": [
        "### Scripts length stats:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrzl7Zpm54Mo"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt \n",
        "\n",
        "lengths = [len(x) for x in tokenized_scripts]\n",
        "bins = list(range(0,250000,10000)) + [250000, 1000000]\n",
        "h, b = np.histogram(lengths, bins=bins)\n",
        "h_cum = np.cumsum(h)\n",
        "nrof_movies = np.sum(h)\n",
        "h_cum_to_show = [str(x)+ ':\\n'+str(round(float(x)/nrof_movies, 3)) for x in h_cum]\n",
        "file_path = os.path.join('/content/drive/MyDrive/NLP/Movie scripts dataset/BERT training data/train_scripts_length.png')\n",
        "bins = [str(bins[i])+'-'+str(bins[i+1])for i in range(len(bins)-1)]\n",
        "show_histogram(bins, h, figsize=(20,10), x_label='Number of tokens', values_to_show= h_cum_to_show, y_label='Number of scripts',\n",
        "               set_rotation=True, title='Scripts length distribution', file_path=file_path,\n",
        "               dpi=200, to_save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "137MDHuSRx_5"
      },
      "source": [
        "## Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNf_-V1mV1GC"
      },
      "source": [
        "class TransformerSA(nn.Module):\n",
        "    def __init__(self, model, confg): \n",
        "        super(TransformerSA, self).__init__()\n",
        "        self.transformer_model = model\n",
        "        \n",
        "        #for param in self.transformer_model.parameters():\n",
        "         #   param.requires_grad = False\n",
        "\n",
        "        #self.cls_ff = torch.nn.Linear(config['train']['embedding_size'], 1)\n",
        "        '''\n",
        "        self.cls_ff = nn.Sequential(\n",
        "            nn.Linear(config['train']['embedding_size'], 3072),\n",
        "            nn.Linear(3072, config['train']['embedding_size']),\n",
        "            nn.LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(config['train']['embedding_size'], config['train']['embedding_size']),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(config['train']['embedding_size'], config['train']['num_classes']),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        '''\n",
        "        self.lstm = LSTM(config['train']['embedding_size'],config['train']['embedding_size'])\n",
        "        self.cls_ff = nn.Linear(config['train']['embedding_size'], config['train']['num_classes'])\n",
        "        #self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, script, input_masks, label):\n",
        "        '''\n",
        "        script squeezed (of size (nrof chunks, max seq len))\n",
        "        '''\n",
        "        #script_vector = []\n",
        "        bert_output = torch.zeros(config['train']['tr_batch_size'], \n",
        "                                  config['train']['max_scene_number'],\n",
        "                                  #config['train']['max_script_length'] // config['train']['max_seq_length'],\n",
        "                                  config['train']['embedding_size'],\n",
        "                                  device=config['train']['device'])\n",
        "        #print(bert_output.shape)\n",
        "        #### ?????!\n",
        "        for i in range(script.shape[1]):   \n",
        "            bert_output[:, i, :] = self.transformer_model(script[:, i, :],\n",
        "                                 attention_mask = input_masks[:, i, :])[1]\n",
        "            '''\n",
        "            outputs = self.transformer_model(script[:, i, :],\n",
        "                                 attention_mask = input_masks[:, i, :], \n",
        "                                 labels=torch.LongTensor([0] * script.shape[0]).to(config['train']['device']),\n",
        "                                 return_dict=True)  \n",
        "\n",
        "            cls_vector = outputs['hidden_states'][-1][0][0]\n",
        "            #print('CLS shape:', cls_vector.shape)\n",
        "            bert_output[:, i, :] = cls_vector ### БЫЛО НЕПРАВИЛЬНО\"!!!!!\n",
        "            #script_vector.append(cls_vector)\n",
        "            '''\n",
        "        output, (_, _) = self.lstm(bert_output.permute(1,0,2))\n",
        "        last_layer = output[-1]\n",
        "        ff_res = self.cls_ff(last_layer)\n",
        "        #stacked = torch.stack(script_vector)\n",
        "        #script_vector = torch.mean(bert_output, 1)\n",
        "        #ff_res = self.cls_ff(script_vector)\n",
        "\n",
        "        return ff_res\n",
        "        #return self.sigmoid(ff_res)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDEP7EQyWocv"
      },
      "source": [
        "## Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7oDR7x1C7U0"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def plot_conf_matr(class_correct, class_total):\n",
        "    results = np.zeros((2,2))\n",
        "    results[0][0] += class_correct[0]\n",
        "    results[1][1] += class_correct[1]\n",
        "    results[0][1] += class_total[0] - class_correct[0]\n",
        "    results[1][0] += class_total[1] - class_correct[1]\n",
        "\n",
        "    df_cm = pd.DataFrame(results.astype(np.int), index = ['not nominated', 'nominated'],\n",
        "                  columns = ['not nominated', 'nominated'])\n",
        "    plt.figure(figsize = (7,7))    \n",
        "    sn.heatmap(df_cm, annot=True, fmt='d')\n",
        "    plt.savefig('conf_matrix.png', bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "def plot_predictions(predictions, trues, file_name='', plot_point_count=200):        \n",
        "    plt.figure(figsize = (7,7))    \n",
        "    plt.scatter(trues[:plot_point_count], predictions[:plot_point_count], marker='.', s=20)\n",
        "    plt.ylabel('Predicted')\n",
        "    plt.xlabel('Actual')\n",
        "    plt.title('Predicted vs true scores')\n",
        "    plt.savefig(file_name + '.png', bbox_inches='tight')\n",
        "    #plt.show()\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPVtA4VzWqKo"
      },
      "source": [
        "class Train():\n",
        "    def __init__(self, config):\n",
        "        self.config = config \n",
        "        transformer_model = BertModel.from_pretrained(\n",
        "                config['train']['pretrained_model_type'],\n",
        "                gradient_checkpointing=True) \n",
        "        '''\n",
        "        transformer_model = self.config['train']['model'].from_pretrained(\n",
        "                config['train']['pretrained_model_type'], \n",
        "                num_labels = self.config['train']['num_classes'],\n",
        "                output_attentions = False, \n",
        "                output_hidden_states = True, \n",
        "                gradient_checkpointing=True\n",
        "                )\n",
        "        '''\n",
        "        self.model = TransformerSA(transformer_model, self.config)\n",
        "        \n",
        "        opt_config = self.config['train']['optim']['AdamW']\n",
        "        for key, val in opt_config.items():\n",
        "            mlflow.log_param(key, val)\n",
        "        mlflow.log_param('nrof_classes', self.config['train']['num_classes'])\n",
        "        \n",
        "        # попробовать SGD??\n",
        "        self.optimizer = AdamW(self.model.parameters(),\n",
        "                  lr = opt_config['lr']#, \n",
        "                  #eps = opt_config['eps'], \n",
        "                  #weight_decay=opt_config['weight_decay'],\n",
        "                )        \n",
        "        #'''\n",
        "        #self.total_steps = self.config['train']['nrof_steps']\n",
        "        #self.scheduler = get_cosine_schedule_with_warmup(self.optimizer, \n",
        "         #                                   num_warmup_steps = 10, \n",
        "          #                                  num_training_steps = self.total_steps)\n",
        "        #self.crit = CrossEntropyLoss()\n",
        "        #self.crit = nn.MSELoss()\n",
        "        #self.crit = nn.BCELoss()\n",
        "        self.crit = nn.BCEWithLogitsLoss()\n",
        "        self.model.to(self.config['train']['device'])\n",
        "        #self.training_stats = []\n",
        "\n",
        "        self.global_step = 0\n",
        "\n",
        "        #mlflow.log_param('total_steps', self.total_steps)\n",
        "    \n",
        "    def save_model(self):\n",
        "        torch.save({\"model\": self.model.state_dict(),\n",
        "                    \"optimizer\": self.optimizer.state_dict(),\n",
        "                    #\"scheduler\": self.scheduler.state_dict(),\n",
        "                    'global_step': self.global_step\n",
        "                    },\n",
        "                   os.path.join(self.config['paths']['ckpt_dir'], \n",
        "                                self.config['train']['exp_name'] + '_checkpoint'))\n",
        "    \n",
        "    def load_model(self):\n",
        "        ckpt = torch.load(os.path.join(self.config['paths']['ckpt_dir'],\n",
        "                                       self.config['train']['exp_name'] + '_checkpoint'),\n",
        "                          map_location=self.config['train']['device'])\n",
        "        self.global_step = ckpt[\"global_step\"] + 1\n",
        "        self.model.load_state_dict(ckpt[\"model\"])   \n",
        "        self.optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "        #self.scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
        "        print(\"Model loaded...\")\n",
        "\n",
        "\n",
        "    def train(self, train_dataloader, validation_dataloader):\n",
        "        if self.config['train']['load_model']:\n",
        "            self.load_model()\n",
        "        self.model.train()\n",
        "        t0 = time()\n",
        "\n",
        "        predicts, trues = [], []\n",
        "        tr_losses = []\n",
        "        cur_loss, nrof_steps, = 0., 0,\n",
        "        nrof_cor_predicts_current, nrof_cor_predicts =0, 0\n",
        "        nrof_samples_current, nrof_samples = 0, 0\n",
        "        print('GLOBAL STEP:', self.global_step)\n",
        "        #class_correct = list(0. for i in range(self.config['train']['num_classes']))\n",
        "        #class_total = list(0. for i in range(self.config['train']['num_classes']))\n",
        "    \n",
        "        #while self.global_step < self.total_steps:\n",
        "        for epoch in range(self.config['train']['nrof_epochs']):\n",
        "            predicts, trues, tr_losses = [], [], []\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                if epoch * len(train_dataloader) + step < self.global_step:\n",
        "                    continue\n",
        "                #if epoch==0 and step<self.global_step:\n",
        "                 #   continue\n",
        "                print('step', step)\n",
        "                print('epoch', epoch)\n",
        "                b_input_ids = batch[0].to(self.config['train']['device'])\n",
        "                b_input_mask = batch[1].to(self.config['train']['device'])\n",
        "                b_labels = batch[2].to(self.config['train']['device'])\n",
        "\n",
        "                \n",
        "                self.model.zero_grad()  \n",
        "                try:\n",
        "                    output = self.model(b_input_ids, \n",
        "                                        b_input_mask, b_labels)\n",
        "                    output = output.squeeze()\n",
        "                    loss = self.crit(output, b_labels)\n",
        "                    tr_losses.append(loss.item())\n",
        "                    cur_loss +=tr_losses[-1]\n",
        "                    #_, predicted = torch.max(output,-1)\n",
        "                    predicted = output.sigmoid()  # should be size = 1?\n",
        "                    predicts.extend(predicted.cpu().detach().numpy().flatten().tolist())\n",
        "                    trues.extend(b_labels.cpu().detach().numpy().flatten().tolist())            \n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "                    self.optimizer.step()\n",
        "                    #self.scheduler.step()\n",
        "                    self.global_step+=1\n",
        "                    nrof_steps+=1\n",
        "                    nrof_samples+=len(b_labels)\n",
        "                except RuntimeError as excp:\n",
        "                    if \"out of memory\" in str(excp):\n",
        "                        print(\"Out of memory!\")\n",
        "                        if hasattr(torch.cuda,'empty_cache'): \n",
        "                            torch.cuda.empty_cache() \n",
        "                    else:\n",
        "                        raise excp\n",
        "\n",
        "                \n",
        "                if self.global_step % 5 == 0: \n",
        "                    elapsed = format_time(time() - t0)\n",
        "                    print('Elapsed: {:}.'.format(elapsed))\n",
        "                    try:\n",
        "                        if self.global_step % 15 == 0: \n",
        "                            avg_val_loss, max_errors, val_predicts, val_trues  = self.validate(validation_dataloader)\n",
        "                            mlflow.log_metric(\"val_loss\", avg_val_loss, self.global_step)\n",
        "                            mlflow.log_metric(\"val_max_error\", max_errors, self.global_step)\n",
        "                            plot_predictions(val_predicts, val_trues, file_name='val_predictions_'+str(self.global_step))\n",
        "                            mlflow.log_artifact('val_predictions_'+str(self.global_step)+'.png')\n",
        "                            self.model.train()\n",
        "                    except RuntimeError as excp:\n",
        "                        if \"out of memory\" in str(excp):\n",
        "                            print(\"Out of memory!VAL\")\n",
        "                            if hasattr(torch.cuda,'empty_cache'): \n",
        "                                torch.cuda.empty_cache() \n",
        "                        else:\n",
        "                            raise excp\n",
        "                    \n",
        "                    if nrof_steps!=0:\n",
        "                        trues, predicts = trues[-50:], predicts[-50:] \n",
        "                        tr_losses = tr_losses[-50:]\n",
        "                        max_errors = max_error(trues,predicts)\n",
        "                        tr_av_loss = np.mean(tr_losses)\n",
        "                        tr_loss = cur_loss / nrof_steps\n",
        "                        #bal_accuracy = balanced_accuracy_score(trues, predicts)\n",
        "                        #if self.global_step % 50 == 0: \n",
        "                         #   plot_predictions(predicts, trues, file_name='train_predictions_'+str(self.global_step))\n",
        "                          #  mlflow.log_artifact('train_predictions_'+str(self.global_step)+'.png')\n",
        "                        mlflow.log_metric(\"train_loss\", tr_loss, self.global_step)\n",
        "                        mlflow.log_metric(\"train_average_loss\", tr_av_loss, self.global_step)\n",
        "                        mlflow.log_metric(\"train_max_error\", max_errors, self.global_step)\n",
        "                        #mlflow.log_metric(\"train_bal_accuracy\", bal_accuracy, self.global_step)\n",
        "                        print('tr loss: {}\\ntr average loss:{}\\nmax errors:{}'.format(tr_loss, tr_av_loss, max_errors))\n",
        "                        print('trues: {}\\npredicts:{}'.format(trues, predicts))\n",
        "                        cur_loss, nrof_steps = 0.,0\n",
        "                        #trues, predicts = [], []\n",
        "                        \n",
        "                \n",
        "\n",
        "                if self.global_step % 15 == 0: \n",
        "                    self.save_model()\n",
        "                    try:\n",
        "                        copytree('/content/mlruns', self.config['paths']['mlruns'] + '_' + self.config['train']['exp_name'] +'_'+str(self.global_step))\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "                        pass \n",
        "\n",
        "            training_time = (time() - t0)\n",
        "        \n",
        "        \n",
        "        self.save_model()\n",
        "        try:\n",
        "            copytree('/content/mlruns', self.config['paths']['mlruns'] + '_' + self.config['train']['exp_name'])\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            pass \n",
        "            \n",
        "\n",
        "\n",
        "    def validate(self, validation_dataloader, to_load=False):\n",
        "        if to_load:\n",
        "            self.load_model()\n",
        "        t1 = time()\n",
        "        self.model.eval()\n",
        "        predicts, trues = [], []\n",
        "        nrof_steps, val_loss, nrof_cor_predicts, nrof_samples = 0, 0., 0, 0\n",
        "        #class_correct = list(0. for i in range(self.config['train']['num_classes']))\n",
        "        #class_total = list(0. for i in range(self.config['train']['num_classes']))\n",
        "\n",
        "        for i, batch in tqdm(enumerate(validation_dataloader)):\n",
        "            with torch.no_grad(): \n",
        "                b_input_ids = batch[0].to(self.config['train']['device'])\n",
        "                b_input_mask = batch[1].to(self.config['train']['device'])\n",
        "                b_labels = batch[2].to(self.config['train']['device'])\n",
        "                output = self.model(b_input_ids, \n",
        "                                    b_input_mask, b_labels)\n",
        "                output = output.squeeze()\n",
        "                val_loss += self.crit(output, b_labels).item()\n",
        "                #val_loss += self.crit(output, b_labels.unsqueeze(-1)).item()\n",
        "                #_, predicted = torch.max(output,-1)\n",
        "                predicted = output.sigmoid()\n",
        "                predicts.extend(predicted.cpu().detach().numpy().flatten().tolist())\n",
        "                trues.extend(b_labels.cpu().detach().numpy().flatten().tolist())            \n",
        "                #if_right = int(predicted == b_labels)\n",
        "                #nrof_cor_predicts += if_right\n",
        "                #nrof_cor_predicts_current += if_right\n",
        "                #class_correct[b_labels.item()] += if_right\n",
        "                #class_total[b_labels.item()] += 1\n",
        "\n",
        "                nrof_steps+=1\n",
        "                nrof_samples+=len(b_labels)\n",
        "                #nrof_samples_current+=len(b_labels)\n",
        "\n",
        "\n",
        "                '''\n",
        "                b_input_ids = batch[0].to(self.config['train']['device'])\n",
        "                #b_input_mask = batch[1].to(self.config['train']['device'])\n",
        "                b_labels = batch[1].to(self.config['train']['device'])\n",
        "                _,_, = self.model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            #attention_mask=b_input_mask,\n",
        "                            labels=b_labels,\n",
        "                            return_dict=True)\n",
        "                val_loss += outputs.loss.item()\n",
        "                _, predicted = torch.max(outputs.logits,-1)\n",
        "                c = (predicted == b_labels)\n",
        "                nrof_cor_predicts += c.sum().item()\n",
        "                for i in range(b_labels.size(0)):\n",
        "                    label = b_labels[i]\n",
        "                    if torch.is_tensor(label):\n",
        "                        for j, ll in enumerate(label):\n",
        "                            class_correct[ll] += c[i][j].squeeze().item()\n",
        "                            class_total[ll] += 1\n",
        "                    else:\n",
        "                        class_correct[label] += c[i].squeeze().item()\n",
        "                        class_total[label] += 1\n",
        "\n",
        "                nrof_samples += len(b_labels)\n",
        "                '''\n",
        "\n",
        "                \n",
        "        #avg_val_accuracy = nrof_cor_predicts / nrof_samples\n",
        "        #val_classes_accs = np.asarray(class_correct) / np.asarray(class_total)\n",
        "        avg_val_loss = val_loss / nrof_steps\n",
        "        max_errors = max_error(trues, predicts)\n",
        "        #avg_bal_accuracy = balanced_accuracy_score(trues, predicts)\n",
        "        validation_time = (time() - t1)\n",
        "        \n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "        \n",
        "        return avg_val_loss, max_errors, predicts, trues\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cNiDxXSIVws"
      },
      "source": [
        "#tr_loader, val_loader, tst_loader = get_data_loaders()\n",
        "T = Train(config)\n",
        "T.train(tr_loader, val_loader)\n",
        "#avg_val_accuracy, avg_val_loss, class_correct, class_total = T.validate(val_loader, to_load=True)\n",
        "#print('val loss: {}\\nval accuracy: {}'.format(avg_val_loss, avg_val_accuracy))\n",
        "#plot_conf_matr(class_correct, class_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI0p-71Ad_oj"
      },
      "source": [
        "#from shutil import copytree\n",
        "\n",
        "copytree('/content/mlruns', '/content/drive/MyDrive/NLP/Movie scripts models/mlruns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFbOiNyZKKwi"
      },
      "source": [
        "!cp -r '/content/drive/MyDrive/NLP/Movie scripts models/BERTScorer/mlruns_script_scorer_360' ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbGhuzxfi2-_"
      },
      "source": [
        "!cp -r '/content/mlruns' '/content/drive/MyDrive/NLP/Movie scripts models/BERTAssess/mlruns_script_scorer_batch_overfit'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saoM3UNbBhDc"
      },
      "source": [
        "for d in val_loader:\n",
        "    print(d[2].shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzGdMyDOMd8b"
      },
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "with mlflow.start_run(run_name=config['train']['exp_name'], run_id='b5bfc0c937af4acebb9233469d310b66'):\n",
        "    tr_loader, val_loader, tst_loader = get_data_loaders()\n",
        "    T = Train(config)\n",
        "    T.train(tr_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mLPCoQWDrhd"
      },
      "source": [
        "mlflow.end_run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym7dPVfDcBNa"
      },
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree('/content/mlruns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CF8W8XGSAbH"
      },
      "source": [
        "import mlflow\n",
        "from pyngrok import ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbkBylrkDAOt"
      },
      "source": [
        "!cp -r '/content/drive/MyDrive/NLP/Movie scripts models/BERTScorer/mlruns_script_scorer_360' ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-_Z93z7-zVf"
      },
      "source": [
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\") # run tracking UI in the background\n",
        "NGROK_AUTH_TOKEN = \"\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq6MuqI5I1_V"
      },
      "source": [
        "ngrok.kill()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nrz37u4yzO0r"
      },
      "source": [
        "# Regression (BoW + Linear regression):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZLFHcULKiW-"
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epw4YIdYzRfV"
      },
      "source": [
        "print(len(os.listdir(config['paths']['script_lemmas'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peMz2H-s0ZV0"
      },
      "source": [
        "## Data preparing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IEchiVEzXyT"
      },
      "source": [
        "def get_train_test_split(tr_imdb_ids, val_imdb_ids, tst_imdb_ids, path_to_script_lemmas):\n",
        "    processed_texts = []\n",
        "    train_inds, val_inds, test_inds = [], [], []\n",
        "    train_labels, train_imdb_ids, val_labels, val_imdb_ids, test_labels, test_imdb_ids = [], [], [], [], [], []\n",
        "\n",
        "    i = 0\n",
        "    for file_name in tqdm(os.listdir(path_to_script_lemmas)):\n",
        "        imdb_id = file_name.split('_')[1]\n",
        "        with open(os.path.join(path_to_script_lemmas, file_name), 'r') as f:\n",
        "            text = f.read()\n",
        "        processed_texts.append(text)\n",
        "        if imdb_id in tr_imdb_ids:\n",
        "            train_inds.append(i)\n",
        "            train_labels.append(imdb_ids_to_labels['tr'][imdb_id].item())\n",
        "            train_imdb_ids.append(imdb_id)\n",
        "        elif imdb_id in val_imdb_ids:\n",
        "            val_inds.append(i)\n",
        "            val_labels.append(imdb_ids_to_labels['val'][imdb_id].item())\n",
        "            val_imdb_ids.append(imdb_id)\n",
        "        elif imdb_id in tst_imdb_ids:\n",
        "            test_inds.append(i)\n",
        "            test_labels.append(imdb_ids_to_labels['tst'][imdb_id].item())\n",
        "            test_imdb_ids.append(imdb_id)\n",
        "        i+=1\n",
        "    return processed_texts, train_inds, val_inds, test_inds, train_labels, val_labels, test_labels, train_imdb_ids, val_imdb_ids, test_imdb_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CyCX3707Zr7"
      },
      "source": [
        "processed_texts, train_inds, val_inds, test_inds, train_labels, val_labels, test_labels, train_imdb_ids, val_imdb_ids, test_imdb_ids = get_train_test_split(tr_imdb_ids, val_imdb_ids, tst_imdb_ids, config['paths']['script_lemmas'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBn0vwRYRmv5"
      },
      "source": [
        "print(len(processed_texts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e29Kd6BKRpDW"
      },
      "source": [
        "print(len(train_inds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rhbwp9CRsf2"
      },
      "source": [
        "print(train_labels[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k5bQpvDHbOL"
      },
      "source": [
        "### Visualize data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZmATNNOHfzH"
      },
      "source": [
        "h, b = np.histogram(train_labels + val_labels + test_labels)\n",
        "#h, b = plt.hist(train_labels)\n",
        "bins = [str(round(b[i], 2)) +'-' + str(round(b[i+1], 2)) for i in range(len(b)-1)]\n",
        "show_histogram(bins, h, values_to_show=None, figsize=(20, 15), x_label='scores', y_label='number of movies',\n",
        "                   set_rotation=True, title='Metacritic scores distriburion', file_path='meta_critic_scores_distribution.png', dpi=100, to_save=True, to_show=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acv5uXmUiKSZ"
      },
      "source": [
        "all_labels = train_labels + val_labels + test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM8Gb57vglzo"
      },
      "source": [
        "scores_mean = np.mean(all_labels)\n",
        "scores_median = np.median(all_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uSEb7Eaij8R"
      },
      "source": [
        "print(scores_mean)\n",
        "print(scores_median)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhyiqV_G1tje"
      },
      "source": [
        "results_df = {'max_features':[], 'binary':[],'norm':[],'use_idf':[], 'smooth_idf':[],\n",
        "              'sublinear_tf':[], 'train_r2_score':[], 'test_r2_score':[], 'test_evs':[],\n",
        "              'test_r2_score_with_mean':[], 'test_r2_score_with_median':[], \n",
        "              'test_evs_with_mean':[], 'test_evs_with_median':[], 'test_mae':[],\n",
        "                'test_mae_with_mean':[], 'test_mae_with_median':[]}\n",
        "\n",
        "nrof_exps = 0\n",
        "for max_features in (1500, 2000):\n",
        "    for binary in (False, True):\n",
        "        for norm in ('l1', 'l2'):\n",
        "            for sublinear_tf in (False, True):\n",
        "                for use_idf in (False, True):\n",
        "                    if use_idf:\n",
        "                        for smooth_idf in (False, True):\n",
        "                            tfidfconverter = TfidfVectorizer(max_features=max_features, min_df=5, max_df=0.7, stop_words=stopwords.words('english'),\n",
        "                                                            binary=binary,norm=norm,use_idf=use_idf,smooth_idf=smooth_idf,sublinear_tf=sublinear_tf)\n",
        "                            X = tfidfconverter.fit_transform(processed_texts).toarray()\n",
        "                            X_train = X[train_inds]\n",
        "                            X_val = X[val_inds]\n",
        "                            X_test = X[test_inds]\n",
        "                            y_train = train_labels\n",
        "                            y_val = val_labels\n",
        "                            y_test = test_labels\n",
        "                            #X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=11)\n",
        "                            #X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=11)\n",
        "                            reg = linear_model.SGDRegressor()\n",
        "                            #clf = svm.LinearSVC(class_weight='balanced', random_state=11)\n",
        "                            reg.fit(X_train, y_train)\n",
        "                            test_r2_score_with_mean = r2_score(y_test, [scores_mean] * len(y_test))\n",
        "                            test_r2_score_with_median = r2_score(y_test, [scores_median] * len(y_test))\n",
        "                            #clf = MLPClassifier(random_state=11, max_iter=10, hidden_layer_sizes =[2500, 2000, 1000, 500, 100], verbose=True).fit(X_train, y_train)\n",
        "                            y_pred = reg.predict(X_test)\n",
        "                            tr_y_pred = reg.predict(X_train)\n",
        "                            test_r2_score = reg.score(X_test, y_test)\n",
        "                            train_r2_score = reg.score(X_train, y_train)\n",
        "                            test_evs =  explained_variance_score(y_test, y_pred)\n",
        "                            test_evs_with_mean = explained_variance_score(y_test, [scores_mean] * len(y_test))\n",
        "                            test_evs_with_median = explained_variance_score(y_test, [scores_median] * len(y_test))\n",
        "                            #bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "                            #tr_bal_acc = balanced_accuracy_score(y_train,tr_y_pred)\n",
        "                            #f1score = f1_score(y_test,y_pred)\n",
        "                            #explained_variance_score(y_true, y_pred)\n",
        "                            #print(balanced_accuracy_score(y_test,y_pred))\n",
        "                            #print(f1_score(y_test,y_pred))\n",
        "                            results_df['max_features'].append(max_features)\n",
        "                            results_df['binary'].append(binary)\n",
        "                            results_df['norm'].append(norm)\n",
        "                            results_df['use_idf'].append(use_idf)\n",
        "                            results_df['smooth_idf'].append(use_idf)\n",
        "                            results_df['sublinear_tf'].append(sublinear_tf)\n",
        "                            results_df['test_r2_score_with_mean'].append(test_r2_score_with_mean)\n",
        "                            results_df['test_r2_score_with_median'].append(test_r2_score_with_median)\n",
        "                            results_df['test_r2_score'].append(test_r2_score)\n",
        "                            results_df['train_r2_score'].append(train_r2_score)\n",
        "                            results_df['test_evs'].append(test_evs)\n",
        "                            results_df['test_evs_with_mean'].append(test_evs_with_mean)\n",
        "                            results_df['test_evs_with_median'].append(test_evs_with_median)\n",
        "                            results_df['test_mae'].append(median_absolute_error(y_test, y_pred))\n",
        "                            results_df['test_mae_with_mean'].append(median_absolute_error(y_test, [scores_mean] * len(y_test)))\n",
        "                            results_df['test_mae_with_median'].append(median_absolute_error(y_test, [scores_median] * len(y_test)))\n",
        "                            #results_df['Train balanced accuracy'].append(round(tr_bal_acc, 4))\n",
        "                            #results_df['Test balanced accuracy'].append(round(bal_acc, 4))\n",
        "                            #results_df['Test f1-score'].append(round(f1score, 4))\n",
        "                            #plot_conf_matr(y_test,y_pred, classes_names=['minor', 'main'], title=)\n",
        "                            #results_df['SVM linear results'].append('Train balanced accuracy: {:.4f}\\nTest balanced accuracy: {:.4f}\\nTest f1-score: {:.4f}'.format(tr_bal_acc, bal_acc, f1score))\n",
        "                            nrof_exps+=1\n",
        "                            print('nrof exps', nrof_exps)\n",
        "                    else:\n",
        "                        tfidfconverter = TfidfVectorizer(max_features=max_features, min_df=5, max_df=0.7, stop_words=stopwords.words('english'),\n",
        "                                                            binary=binary,norm=norm,use_idf=use_idf,sublinear_tf=sublinear_tf)\n",
        "                        X = tfidfconverter.fit_transform(processed_texts).toarray()\n",
        "                        X_train = X[train_inds]\n",
        "                        X_val = X[val_inds]\n",
        "                        X_test = X[test_inds]\n",
        "                        y_train = train_labels\n",
        "                        y_val = val_labels\n",
        "                        y_test = test_labels\n",
        "                        #X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=11)\n",
        "                        #X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=11)\n",
        "                        reg = linear_model.SGDRegressor()\n",
        "                        #clf = svm.LinearSVC(class_weight='balanced', random_state=11)\n",
        "                        reg.fit(X_train, y_train)\n",
        "                        #clf = MLPClassifier(random_state=11, max_iter=10, hidden_layer_sizes =[2500, 2000, 1000, 500, 100], verbose=True).fit(X_train, y_train)\n",
        "                        y_pred = reg.predict(X_test)\n",
        "                        tr_y_pred = reg.predict(X_train)\n",
        "                        test_r2_score_with_mean = r2_score(y_test, [scores_mean] * len(y_test))\n",
        "                        test_r2_score_with_median = r2_score(y_test, [scores_median] * len(y_test))\n",
        "                        train_r2_score = reg.score(X_train, y_train)\n",
        "                        test_evs =  explained_variance_score(y_test, y_pred)\n",
        "                        test_evs_with_mean = explained_variance_score(y_test, [scores_mean] * len(y_test))\n",
        "                        test_evs_with_median = explained_variance_score(y_test, [scores_median] * len(y_test))\n",
        "                        #bal_acc = balanced_accuracy_score(y_test,y_pred)\n",
        "                        #tr_bal_acc = balanced_accuracy_score(y_train,tr_y_pred)\n",
        "                        #f1score = f1_score(y_test,y_pred)\n",
        "                        #print(balanced_accuracy_score(y_test,y_pred))\n",
        "                        #print(f1_score(y_test,y_pred))\n",
        "                        results_df['max_features'].append(max_features)\n",
        "                        results_df['binary'].append(binary)\n",
        "                        results_df['norm'].append(norm)\n",
        "                        results_df['use_idf'].append(use_idf)\n",
        "                        results_df['smooth_idf'].append(False)\n",
        "                        results_df['sublinear_tf'].append(sublinear_tf)\n",
        "                        results_df['test_r2_score_with_mean'].append(test_r2_score_with_mean)\n",
        "                        results_df['test_r2_score_with_median'].append(test_r2_score_with_median)\n",
        "                        results_df['test_r2_score'].append(test_r2_score)\n",
        "                        results_df['train_r2_score'].append(train_r2_score)\n",
        "                        results_df['test_evs'].append(test_evs)\n",
        "                        results_df['test_evs_with_mean'].append(test_evs_with_mean)\n",
        "                        results_df['test_evs_with_median'].append(test_evs_with_median)\n",
        "                        results_df['test_mae'].append(median_absolute_error(y_test, y_pred))\n",
        "                        results_df['test_mae_with_mean'].append(median_absolute_error(y_test, [scores_mean] * len(y_test)))\n",
        "                        results_df['test_mae_with_median'].append(median_absolute_error(y_test, [scores_median] * len(y_test)))\n",
        "                        #results_df['Train balanced accuracy'].append(round(tr_bal_acc, 4))\n",
        "                        #results_df['Test balanced accuracy'].append(round(bal_acc, 4))\n",
        "                        #results_df['Test f1-score'].append(round(f1score, 4))\n",
        "                        #results_df['SVM linear results'].append('Train balanced accuracy: {:.4f}\\nTest balanced accuracy: {:.4f}\\nTest f1-score: {:.4f}'.format(tr_bal_acc, bal_acc, f1score))\n",
        "                        nrof_exps+=1\n",
        "                        print('nrof exps', nrof_exps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDIHeO6ef_H8"
      },
      "source": [
        "results_df = pd.DataFrame(results_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11pnMlpp2ApT"
      },
      "source": [
        "results_df.to_excel('BoW_validation_results_metascores.xlsx', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U8rwZVggLpE"
      },
      "source": [
        "results_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--3Mbmin4Wud"
      },
      "source": [
        "tfidfconverter = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.7, stop_words=stopwords.words('english'),\n",
        "                                                            binary=False,norm='l2',use_idf=True,smooth_idf = True, sublinear_tf=False)\n",
        "X = tfidfconverter.fit_transform(processed_texts).toarray()\n",
        "X_train = X[train_inds]\n",
        "X_val = X[val_inds]\n",
        "X_test = X[test_inds]\n",
        "y_train = train_labels\n",
        "y_val = val_labels\n",
        "y_test = test_labels\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=11)\n",
        "#X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=11)\n",
        "reg = linear_model.SGDRegressor()\n",
        "#clf = svm.LinearSVC(class_weight='balanced', random_state=11)\n",
        "reg.fit(X_train, y_train)\n",
        "#test_r2_score_with_mean = r2_score(y_test, [scores_mean] * len(y_test))\n",
        "#test_r2_score_with_median = r2_score(y_test, [scores_median] * len(y_test))\n",
        "#clf = MLPClassifier(random_state=11, max_iter=10, hidden_layer_sizes =[2500, 2000, 1000, 500, 100], verbose=True).fit(X_train, y_train)\n",
        "y_pred = reg.predict(X_test)\n",
        "tr_y_pred = reg.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXh29RBL_A4z"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5Wp4DUH_TUW"
      },
      "source": [
        "nrof_texts_to_write = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ9ewHEeEl05"
      },
      "source": [
        "for i, text in enumerate(processed_texts):\n",
        "    if i in train_inds:\n",
        "        label = train_labels[train_inds.index(i)]\n",
        "        imdb_id = train_imdb_ids[train_inds.index(i)]\n",
        "        with open(os.path.join(config['paths']['meta_score_exampels'], str(round(label * 100))+'_'+str(imdb_id)+'.txt'), 'w') as f:\n",
        "                  f.write(text)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}