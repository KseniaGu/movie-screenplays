{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransformerScriptQualityAssessor_2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "xvUr47y2j7Xf",
        "e-et7ioyS9Ci",
        "137MDHuSRx_5",
        "kDEP7EQyWocv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d56TcrF5KjkM"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install mlflow --quiet\n",
        "!pip install pyngrok --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U0aSUcF0Bts"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ450w4omB3d"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI3h-Gl1rZ5x"
      },
      "source": [
        "import os \n",
        "import torch \n",
        "import pickle \n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "import seaborn as sn\n",
        "from matplotlib import pyplot as plt \n",
        "from torch.nn import LSTM\n",
        "import torch.nn.functional as F\n",
        "import numpy as np \n",
        "import datetime\n",
        "import random\n",
        "from collections import Counter\n",
        "from shutil import copytree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, LongformerTokenizer, \\\n",
        "    LongformerForSequenceClassification, BertForSequenceClassification,AdamW,\\\n",
        "    get_cosine_schedule_with_warmup, BertTokenizerFast, BertModel\n",
        "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import torch.nn as nn\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torch.optim as Opt\n",
        "#torch.set_default_tensor_type(torch.HalfTensor)\n",
        "#torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
        "import mlflow\n",
        "from pyngrok import ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1IGt8kM34Oe"
      },
      "source": [
        "!cp '/content/as_tokenized_script_chunks.pickle'  '/content/drive/MyDrive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_EBOjmI4ADS"
      },
      "source": [
        "!cp '/content/as_scripts.pickle'  '/content/drive/MyDrive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9VQllQQr9A1"
      },
      "source": [
        "config = { \n",
        "        'paths': { \n",
        "            #'nominated_movies': '/content/drive/MyDrive/NLP/Movie scripts dataset/BERT training data/Screenplay awards data/all_awards_movies.pickle',\n",
        "            'scripts' : '/content/drive/MyDrive/NLP/Movie scripts dataset/Movie scripts and annotations/Scripts',\n",
        "            #'movies_matching_scores' : '/content/drive/MyDrive/NLP/Movie scripts dataset/Movie characters/Matching evaluation and statistics/movies_mean_matching_scores.xlsx',\n",
        "            #'logs_dir':'/content/drive/MyDrive/NLP/Movie scripts models/BERTAssess/logs',\n",
        "            'ckpt_dir': '/content/drive/MyDrive/NLP/Movie scripts models/BERTAssess/ckpts',\n",
        "            #'ckpt_dir': '/content/ckpts',\n",
        "            #'ckpt_to_load': '/content/drive/MyDrive/NLP/Movie scripts models/BERTAssess/ckpts/script_genre_classification_10_scenes_average_checkpoint_985',\n",
        "            'ckpt_to_load': '/content/drive/MyDrive/NLP/Movie scripts models/BERTAssess/ckpts/script_genre_classification_10_scenes_average_checkpoint_398',\n",
        "            'script_annotations': '/content/drive/MyDrive/NLP/Movie scripts dataset/Movie scripts and annotations/Script annotations by BERT/row_classification',\n",
        "            #\n",
        "            #'model_annotations': '/content/drive/MyDrive/NLP/Movie scripts dataset/Movie scripts and annotations/Script annotations by BERT',\n",
        "            #'manual_annotations': '/content/drive/MyDrive/NLP/Movie scripts dataset/Movie scripts and annotations/Script manual annotations',\n",
        "             'mlruns': '/content/drive/MyDrive/NLP/Movie scripts models/BERTAssess/mlruns',\n",
        "             'script_lemmas':'/content/drive/MyDrive/NLP/Movie scripts dataset/Movie scripts and annotations/Scripts_lemmas',\n",
        "             'task_to_labels': '/content/drive/MyDrive/NLP/Movie scripts dataset/BERT training data/Script texts/script_task_to_labels_dicts.pickle'\n",
        "        },\n",
        "        'train': {\n",
        "                'optim' : {\n",
        "                    'AdamW':{\n",
        "                        'lr':1e-5,\n",
        "                        'eps': 1e-8,\n",
        "                        'weight_decay':0.0001\n",
        "                    }\n",
        "                },\n",
        "                #'grad_accum_iters': 2, \n",
        "                'embedding_size': 768, \n",
        "                'model': BertForSequenceClassification, # from [BertForSequenceClassification, LongformerForSequenceClassification]\n",
        "                'tokenizer':BertTokenizerFast, # from [BertTokenizer, LongformerTokenizer]\n",
        "                'pretrained_model_type': 'bert-base-cased', # from ['bert-base-cased', 'allenai/longformer-base-4096']\n",
        "                #'max_script_length' : 65540, #  131072, 65540, 32770\n",
        "                'max_seq_length' : 512,\n",
        "                'num_classes' : 2, # [2, 13]\n",
        "                'max_scene_number' : 100, \n",
        "                'nrof_steps_for_shed' : 800,\n",
        "                'nrof_epochs' : 2,  \n",
        "                'tr_batch_size' : 4,\n",
        "                'tst_batch_size' : 4,\n",
        "                'exp_name':'script_awards_classification_100_scenes_average', \n",
        "                'task_name':'script_awards',\n",
        "                'classes_names': {'genre':['Comedy', 'Short', 'Thriller', 'Documentary', 'Horror', 'Biography', 'Mystery', \n",
        "                                           'Animation', 'Crime', 'Adventure', 'Action', 'Drama', 'Fantasy'],\n",
        "                                  'script_awards':['Not nominated', 'Nominated']\n",
        "                                  },\n",
        "                'use_intermediate_weights': False,\n",
        "                'device': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "                #'heading_to_class_map': {'scene_heading':0, 'text':1, 'speaker_heading':2, 'dialog':3},\n",
        "                #'class_to_heading_map': {0:'scene_heading', 1:'text', 2:'speaker_heading', 3:'dialog'},\n",
        "                'load_model':False\n",
        "                }\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmp0F-FWj4tF"
      },
      "source": [
        "with open('/content/drive/MyDrive/labels.pickle', 'rb') as f:\n",
        "    labels = pickle.load(f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qiks0gZkP8Z"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNAU-XRRUI3K"
      },
      "source": [
        "genre_classes_names=['News', 'Western', 'Musical', 'Thriller', 'Family', 'Animation',\n",
        "                                                         'Action', 'History', 'Biography', 'Crime', 'Mystery', 'War', 'Sci-Fi', \n",
        "                                                        'Fantasy', 'Music', 'Film-Noir', 'Horror', 'Talk-Show', 'Adventure', 'Romance']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tm-r5nSBGRq"
      },
      "source": [
        "with open(config['paths']['task_to_labels'], 'rb') as f:\n",
        "    task_to_labels_dicts = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDTyQBKMdqW3"
      },
      "source": [
        "with open(config['paths']['task_to_labels'], 'wb') as f:\n",
        "    pickle.dump(task_to_labels_dicts, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoUVxfgY4PZZ"
      },
      "source": [
        "print(task_to_labels_dicts.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiVkK6YcBNL8"
      },
      "source": [
        "print(task_to_labels_dicts['genre'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7a5FNLRyGB2"
      },
      "source": [
        "print(list(set(task_to_labels_dicts['genre'].values())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR6ceMmkddqq"
      },
      "source": [
        "print(task_to_labels_dicts['genre'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6VIK7Zhc6Cp"
      },
      "source": [
        "print(-1 in task_to_labels_dicts['genre'].values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MyrsGmIWn4M"
      },
      "source": [
        "task_to_labels_dicts['genre'] = dict([(str(k).rjust(7,'0'), v) for k, v in task_to_labels_dicts['genre'].items()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNiayJeZbfwe"
      },
      "source": [
        "new_dict = {}\n",
        "for key, value in task_to_labels_dicts['genre'].items():\n",
        "    new_dict[str(key).rjust('0')] = value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP8-jSzadOns"
      },
      "source": [
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbMLYWt6WdEC"
      },
      "source": [
        "print(task_to_labels_dicts['script_awards'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnByAiK9Whb5"
      },
      "source": [
        "print(task_to_labels_dicts['meta_scores'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ehMtohGdoKc"
      },
      "source": [
        "print(task_to_labels_dicts['meta_scores'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cqqKmpmdmRV"
      },
      "source": [
        "task_to_labels_dicts['meta_scores'] = dict([(str(k).rjust(7,'0'), v) for k, v in task_to_labels_dicts['meta_scores'].items()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBvLq6frWjcu"
      },
      "source": [
        "print(task_to_labels_dicts['year'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0dt4ofEdkGL"
      },
      "source": [
        "print(task_to_labels_dicts['year'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFdK86_QdiB4"
      },
      "source": [
        "task_to_labels_dicts['year'] = dict([(str(k).rjust(7,'0'), v) for k, v in task_to_labels_dicts['year'].items()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1Tk4uuf5Ea6"
      },
      "source": [
        "with open('/content/labels.pickle', 'rb') as f:\n",
        "    labels = pickle.load(f)\n",
        "print(len(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-_zR6mLQIA2"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ixBk9LXQLBU"
      },
      "source": [
        "counter = Counter(task_to_labels_dicts['genre'].values())\n",
        "print(counter)\n",
        "print(counter['Comedy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiqnEh1RBQCI"
      },
      "source": [
        "print(len(set(task_to_labels_dicts['genre'].values())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlWHdrr-Bf3E"
      },
      "source": [
        "genre_list = list(set(task_to_labels_dicts['genre'].values()))\n",
        "genre_dict = dict(zip(genre_list, range(len(genre_list))))\n",
        "print(genre_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUW1eUluCu0a"
      },
      "source": [
        "## Some stuff:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWEFsK_TdRl0"
      },
      "source": [
        "path_to_awards = '/content/drive/MyDrive/NLP/Movie scripts dataset/BERT training data/Screenplay awards data'\n",
        "events = ('Academy Awards adapted screenplay', 'Academy Awards original screenplay',\n",
        "          'BAFTA nominations', 'Golden Globe Award for Best Screenplay',\n",
        "          'Writers Guild Awards Winners & Nominees 2020-2013')\n",
        "file_names  =('academy_awards_adapted_screenplay_movies', 'academy_awards_original_screenplay_movies',\n",
        "              'bafta_screenplay_movies', 'golden_globe_best_screenplay_movies',\n",
        "              'writers_guild_awards_movies')\n",
        "\n",
        "movies_awards = {}\n",
        "\n",
        "for event, file_name in zip(events,file_names):\n",
        "    with open(os.path.join(path_to_awards, file_name + '.pickle'), 'rb') as f:\n",
        "        movies = pickle.load(f)\n",
        "    for movie in movies:\n",
        "        if movie in movies_awards:\n",
        "            movies_awards[movie].append(event)\n",
        "        else:\n",
        "            movies_awards[movie]=[event]\n",
        "\n",
        "awards_df = {'movie':[], 'Academy Awards adapted screenplay':[],\n",
        "             'Academy Awards original screenplay':[], 'BAFTA nominations':[],\n",
        "             'Golden Globe Award for Best Screenplay':[], \n",
        "             'Writers Guild Awards Winners & Nominees 2020-2013':[]}\n",
        "for movie in movies_awards:\n",
        "    awards_df['movie'].append(movie.split('.')[0])\n",
        "    for key in events:\n",
        "        if key in movies_awards[movie]:\n",
        "            awards_df[key].append('+')\n",
        "        else:\n",
        "            awards_df[key].append('-')\n",
        "\n",
        "\n",
        "awards_df = pd.DataFrame(awards_df)\n",
        "print(awards_df.head())\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_MvUq24rc8c"
      },
      "source": [
        "## Dataset preprocessing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvUr47y2j7Xf"
      },
      "source": [
        "### Additional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWJpn6lDANzE"
      },
      "source": [
        "nominated_movies_imdb_ids, not_nominated_movies = choose_imdb_ids_for_training(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUQtsHzK9Zkt"
      },
      "source": [
        "scripts_awards_df = {'scripts':[], 'label':[]}\n",
        "\n",
        "for file_name in tqdm(os.listdir(config['paths']['scripts'])):\n",
        "    imdb_id = file_name.split('_')[1].replace('.txt','')\n",
        "    text = read_script(os.path.join(config['paths']['scripts'], file_name))\n",
        "    scripts_awards_df['scripts'].append(text)\n",
        "    scripts_awards_df['label'].append(int(imdb_id in nominated_movies_imdb_ids))\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRmGSxqdKDp8"
      },
      "source": [
        "scripts_awards_df = pd.DataFrame(scripts_awards_df)\n",
        "scripts_awards_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc2KMIQIKoKC"
      },
      "source": [
        "with open('scripts_awards_df.pickle', 'wb') as f:\n",
        "    pickle.dump(scripts_awards_df, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB340kZuMe_x"
      },
      "source": [
        "!cp 'scripts_awards_df.pickle' '/content/drive/MyDrive/NLP/Movie scripts dataset/BERT training data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h9qP_iVkAST"
      },
      "source": [
        "### Main:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E1NttXl_h0d"
      },
      "source": [
        "tokenizer = config['train']['tokenizer'].from_pretrained(config['train']['pretrained_model_type'], \n",
        "                                          do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULIu2ojM3DgD"
      },
      "source": [
        "'''\n",
        "def choose_imdb_ids_for_training(config, nrof_not_nominated = 5000):\n",
        "    with open(config['paths']['nominated_movies'], 'rb') as f:\n",
        "        nominated_movies = pickle.load(f)\n",
        "    nominated_movies_imdb_ids = [x.split('_')[1].split('.')[0] for x in  nominated_movies]\n",
        "    mean_matching_scores_df = pd.read_excel(config['paths']['movies_matching_scores'])\n",
        "    imdb_ids = mean_matching_scores_df[mean_matching_scores_df.iou_values_mean<1.]['imdb_id'].tolist()\n",
        "    imdb_ids = [str(x).rjust(7,'0') for x in imdb_ids]\n",
        "    not_nominated_movies = [x for x in imdb_ids if not x in nominated_movies_imdb_ids]\n",
        "\n",
        "    return nominated_movies_imdb_ids, not_nominated_movies[:nrof_not_nominated]\n",
        "'''\n",
        "def read_script(path):\n",
        "    try:\n",
        "        with open(path, 'r') as f:\n",
        "            text = f.read()\n",
        "    except:\n",
        "        with open(path, 'r', encoding='latin-1') as f:\n",
        "            text = f.read()\n",
        "\n",
        "    return text \n",
        "\n",
        "def show_histogram(x_data, y_data, values_to_show=None, figsize=(40, 10), x_label='x', y_label='y',\n",
        "                   set_rotation=False, rotation_angle=45, title='title', file_path='name.png', dpi=100, to_save=False, to_show=True):\n",
        "\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    h = sns.barplot(x=x_data, y=y_data, palette=\"Blues_d\")\n",
        "    if values_to_show:\n",
        "        for i,y in enumerate(y_data):\n",
        "            h.text(i, y, str(y)+'\\n('+str(values_to_show[i]) + ')', color='black', ha='center')\n",
        "    if set_rotation:\n",
        "        h.set_xticklabels(h.get_xticklabels(), rotation=rotation_angle)\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.title(title)\n",
        "    if to_show:\n",
        "        plt.show()\n",
        "\n",
        "    if to_save:\n",
        "        fig.savefig(file_path, dpi=dpi, bbox_inches='tight')\n",
        "        \n",
        "def remove_labels(row):\n",
        "    if row.startswith('text:'):\n",
        "        row = row[6:]\n",
        "    elif row.startswith('dialog:'):\n",
        "        row = row[8:]\n",
        "    elif row.startswith('speaker_heading:'):\n",
        "        row = row[17:]\n",
        "    elif row.startswith('scene_heading:'):\n",
        "        row = row[15:]\n",
        "    return row.strip()\n",
        "\n",
        "'''\n",
        "def plot_conf_matr(trues, predicts, title='tr_'):\n",
        "    results = np.zeros((2,2))\n",
        "    for t, p in zip(trues, predicts):\n",
        "            results [t][p]+=1\n",
        "    df_cm = pd.DataFrame(results.astype(np.int), index = ['not nominated', 'nominated'],\n",
        "                  columns = ['not nominated', 'nominated'])\n",
        "    plt.figure(figsize = (7,7))    \n",
        "    sn.heatmap(df_cm, annot=True, fmt='d')\n",
        "    plt.savefig(title+'conf_matrix.png', bbox_inches='tight')\n",
        "    plt.close()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG_WrVq-rhlA"
      },
      "source": [
        "class ScriptData:\n",
        "    def __init__(self, config, tokenizer):\n",
        "        self.config = config \n",
        "        self.tokenizer = tokenizer\n",
        "        self.imdb_to_labels_dict = self.get_labels_dict()\n",
        "        self.scripts, self.labels, self.imdb_ids = self._get_scripts_and_labels(to_load=True)\n",
        "        print('Labels:', self.labels[:10])\n",
        "        self.scripts_scenes = self.get_script_scenes()\n",
        "    \n",
        "    def get_labels_dict(self):\n",
        "        with open(self.config['paths']['task_to_labels'], 'rb') as f:\n",
        "            task_to_labels_dict = pickle.load(f)\n",
        "        if self.config['train']['task_name']=='genre':\n",
        "            self.genre_dict = dict(zip(self.config['train']['classes_names']['genre'], \n",
        "                                       range(len(self.config['train']['classes_names']['genre']))))\n",
        "            #self.genre_dict = dict(zip(genre_list, range(len(genre_list))))\n",
        "            print(self.genre_dict)\n",
        "            #genre_list = list(set(task_to_labels_dict['genre'].values()))\n",
        "            #genre_list = [x for x in genre_list if not x==-1]\n",
        "            #self.genre_dict = dict(zip(genre_list, range(len(genre_list))))  \n",
        "            #self.classes_names = genre_list\n",
        "        elif self.config['train']['task_name']=='script_awards':\n",
        "            ...\n",
        "            #self.classes_names = ['not_nominated', 'nominated']\n",
        "        return task_to_labels_dict[self.config['train']['task_name']]\n",
        "\n",
        "    def prepare_label(self, label):\n",
        "        if self.config['train']['task_name']=='genre':\n",
        "            return self.genre_dict[label]\n",
        "        else:\n",
        "            return label \n",
        "\n",
        "    def _get_scripts_and_labels(self, to_load=False):\n",
        "        label_counter = Counter(self.imdb_to_labels_dict.values())\n",
        "        #with open(self.config['paths']['labels'], 'rb') as f:\n",
        "         #   imdb_id_to_label_mapping = pickle.load(f)\n",
        "        #nominated_movies_imdb_ids, not_nominated_movies_imdb_ids = \\\n",
        "         #               choose_imdb_ids_for_training(self.config)\n",
        "        if not (to_load and os.path.exists('scripts.pickle') and os.path.exists('labels.pickle')):\n",
        "            scripts, labels, imdb_ids = [], [], []\n",
        "            for file_name in tqdm(os.listdir(self.config['paths']['script_annotations'])):\n",
        "                imdb_id = file_name.split('_')[1]\n",
        "                if imdb_id in self.imdb_to_labels_dict:\n",
        "                    if self.imdb_to_labels_dict[imdb_id]!=-1 and label_counter[self.imdb_to_labels_dict[imdb_id]]>10:\n",
        "                        with open(os.path.join(self.config['paths']['script_annotations'], file_name), 'r') as f:\n",
        "                            anno_lines = f.readlines()\n",
        "                        #text = read_script(os.path.join(self.config['paths']['scripts'], file_name))\n",
        "                        scripts.append(anno_lines)\n",
        "                        #labels.append(int(imdb_id in nominated_movies_imdb_ids))\n",
        "                        labels.append(self.prepare_label(self.imdb_to_labels_dict[imdb_id]))\n",
        "                        imdb_ids.append(imdb_id)\n",
        "            with open('scripts.pickle', 'wb') as f:\n",
        "                pickle.dump(scripts, f)\n",
        "            with open('labels.pickle', 'wb') as f:\n",
        "                pickle.dump(labels, f)\n",
        "            with open('imdb_ids.pickle', 'wb') as f:\n",
        "                pickle.dump(imdb_ids, f)\n",
        "            print('Data saved')\n",
        "        else:\n",
        "            with open('scripts.pickle', 'rb') as f:\n",
        "                scripts = pickle.load(f)\n",
        "            with open('labels.pickle', 'rb') as f:\n",
        "                labels = pickle.load(f)\n",
        "            with open('imdb_ids.pickle', 'rb') as f:\n",
        "                imdb_ids = pickle.load(f)\n",
        "            print('Data loaded')\n",
        "\n",
        "        \n",
        "        return scripts, labels, imdb_ids\n",
        "    '''\n",
        "    def preprocess_text(self, text):\n",
        "        text = re.sub(\" +|\\n+|\\r|\\t|\\0|\\x0b|\\xa0|\\x80|\\x93|\\x99\", ' ', text).strip()\n",
        "        text = ' '.join(re.findall(r'[a-zA-Z0-9!\"#%&\\'()+,\\-\\./:;?\\[\\]]+', text)).strip()\n",
        "        text = re.sub(' \\.', '.', text)\n",
        "        return text\n",
        "    '''\n",
        "    def make_weights_for_balanced_classes(self, labels):     \n",
        "        nclasses = self.config['train']['num_classes']\n",
        "        count = [0] * nclasses\n",
        "\n",
        "        for label in labels:                                                         \n",
        "            count[label] += 1                                                     \n",
        "        weight_per_class = [0.] * nclasses                                     \n",
        "        N = float(sum(count))                                                   \n",
        "        for i in range(nclasses):                                                   \n",
        "            if count[i]!=0:\n",
        "                weight_per_class[i] = N/float(count[i])                                 \n",
        "            else:\n",
        "                weight_per_class[i] = 1000\n",
        "        weight = [0] * len(labels)                                              \n",
        "        for idx, label in enumerate(labels):                                          \n",
        "            weight[idx] = weight_per_class[label]\n",
        "\n",
        "        print('Weights per class:', weight_per_class)\n",
        "        return weight, weight_per_class\n",
        "    '''\n",
        "    def tokenize_scripts(self, to_load=True):\n",
        "        if to_load and os.path.exists('tokenized_scripts.pickle'):\n",
        "            with open('tokenized_scripts.pickle', 'rb') as f:\n",
        "                tokenized_scripts = pickle.load(f)\n",
        "        else:\n",
        "            tokenized_scripts = self.tokenizer(self.scripts)['input_ids']\n",
        "            tokenized_scripts = [x[1:] for x in tokenized_scripts] # remove cls \n",
        "            with open('tokenized_scripts.pickle', 'wb') as f:\n",
        "                pickle.dump(tokenized_scripts, f)\n",
        "        return tokenized_scripts\n",
        "    '''\n",
        "    def prepare_tokenized_chunks_masks_labels(self, \n",
        "                                              tokenized_script_chunks, \n",
        "                                              attention_masks,\n",
        "                                              labels,\n",
        "                                              imdb_ids):\n",
        "        tokenized_script_chunks = [torch.tensor(chunk) for chunk in tokenized_script_chunks]\n",
        "        attention_masks = [torch.tensor(mask) for mask in attention_masks]\n",
        "        padded_tokenized_script_chunks = pad_sequence(tokenized_script_chunks, \n",
        "                                                      padding_value=0, batch_first=True)# for BERT pad = 0 ?\n",
        "        padded_attention_masks = pad_sequence(attention_masks, \n",
        "                                              padding_value=0, batch_first=True)\n",
        "        labels = torch.LongTensor(labels)\n",
        "        imdb_ids = [int(x) if x else 0 for x in imdb_ids]\n",
        "        imdb_ids = torch.LongTensor(imdb_ids)\n",
        "\n",
        "        return padded_tokenized_script_chunks, padded_attention_masks, labels, imdb_ids\n",
        "\n",
        "    def get_script_scenes(self):\n",
        "        scripts_scenes = []\n",
        "\n",
        "        scene_text = ''\n",
        "        for i, script_lines in enumerate(self.scripts):\n",
        "            scripts_scenes.append([])\n",
        "            for line_num, line in enumerate(script_lines):\n",
        "                if line.startswith('scene_heading:'):\n",
        "                    if scene_text:\n",
        "                        scripts_scenes[-1].append(scene_text)\n",
        "                    scene_text = remove_labels(line)\n",
        "                else:\n",
        "                    scene_text+=remove_labels(line)\n",
        "            if not scripts_scenes[-1]:\n",
        "                scripts_scenes.pop(-1)\n",
        "                self.labels.pop(i)\n",
        "                self.imdb_ids.pop(i)\n",
        "\n",
        "        return scripts_scenes\n",
        "\n",
        "    def make_tokenized_chunks_for_scripts(self, to_load=True):\n",
        "        if not (to_load and os.path.exists('tokenized_script_chunks.pickle') and os.path.exists('attention_masks.pickle')):\n",
        "            tokenized_script_chunks, attention_masks = [], []\n",
        "            text_iterator = self.scripts_scenes #if self.config['train']['scene_as_chunk'] else self.scripts \n",
        "\n",
        "            for script_scenes in tqdm(text_iterator):\n",
        "                if len(script_scenes)>0:\n",
        "                    tokenized_scenes = self.tokenizer(script_scenes, truncation=True, \n",
        "                                                    padding='max_length',\n",
        "                                                    return_attention_mask=True) #['input_ids']\n",
        "                    random_indices = sorted(random.sample(range(len(tokenized_scenes['input_ids'])), k =min(len(tokenized_scenes['input_ids']),\n",
        "                                                                                                            self.config['train']['max_scene_number'])))\n",
        "                    #print('random indices:', random_indices)\n",
        "                    #print()\n",
        "                    tokenized_scenes_ids = tokenized_scenes['input_ids']\n",
        "                    tokenized_scenes_ids = [x for i, x in enumerate(tokenized_scenes_ids) if i in random_indices]\n",
        "                    #tokenized_scenes_attention_masks = tokenized_scenes['attention_mask'][:self.config['train']['max_scene_number']]\n",
        "                    tokenized_scenes_attention_masks = tokenized_scenes['attention_mask']\n",
        "                    tokenized_scenes_attention_masks = [x for i, x in enumerate(tokenized_scenes_attention_masks) if i in random_indices]\n",
        "                    tokenized_script_chunks.append(tokenized_scenes_ids)\n",
        "                    attention_masks.append(tokenized_scenes_attention_masks)\n",
        "            with open('tokenized_script_chunks.pickle', 'wb') as f:\n",
        "                pickle.dump(tokenized_script_chunks, f)\n",
        "            with open('attention_masks.pickle', 'wb') as f:\n",
        "                pickle.dump(attention_masks, f)\n",
        "        else:\n",
        "            with open('tokenized_script_chunks.pickle', 'rb') as f:\n",
        "                tokenized_script_chunks = pickle.load(f)\n",
        "            with open('attention_masks.pickle', 'rb') as f:\n",
        "                attention_masks = pickle.load(f)\n",
        "                \n",
        "        return tokenized_script_chunks, attention_masks\n",
        "\n",
        "        '''\n",
        "        def make_tokenized_chunks_for_scripts(self, to_load=False):\n",
        "            tokenized_scripts = self.tokenize_scripts()\n",
        "            tokenized_script_chunks, attention_masks = [], []\n",
        "            max_script_l = self.config['train']['max_script_length']\n",
        "            max_seq_l = self.config['train']['max_seq_length']\n",
        "            n = int(max_script_l / (max_seq_l//2)) - 1\n",
        "            \n",
        "            for t_script in tqdm(tokenized_scripts):    \n",
        "                t_script = t_script[:max_script_l]\n",
        "                n = int(len(t_script) / (max_seq_l))\n",
        "                script_chunks_masks = [(t_script[i*(max_seq_l):i*(max_seq_l) + max_seq_l - 1], [1]*(min(max_seq_l, len(t_script) - i*(max_seq_l - 1)))) for i in range(n)]\n",
        "\n",
        "                if len(script_chunks_masks[-1][0]) < max_seq_l - 1:\n",
        "                    script_chunks_masks[-1] = (script_chunks_masks[-1][0] + [1] * (max_seq_l -1 - len(script_chunks_masks[-1][0])),\n",
        "                                            script_chunks_masks[-1][1] + [0] * (max_seq_l -1 - len(script_chunks_masks[-1][1])))\n",
        "                \n",
        "                script_chunks, script_masks = zip(*script_chunks_masks)\n",
        "                script_chunks = [[101] + x for x in script_chunks]\n",
        "                script_masks = [[1] + x for x in script_masks]\n",
        "                tokenized_script_chunks.append(script_chunks)\n",
        "                attention_masks.append(script_masks)\n",
        "\n",
        "            return tokenized_scripts, tokenized_script_chunks, attention_masks\n",
        "        '''\n",
        "    def get_train_val_split(self):\n",
        "        tokenized_script_chunks, attention_masks = self.make_tokenized_chunks_for_scripts()\n",
        "        tr_inputs, val_inputs, tr_masks, val_masks, tr_labels, val_labels, tr_imdb_ids, val_imdb_ids = train_test_split(\n",
        "            tokenized_script_chunks, attention_masks, self.labels,  self.imdb_ids,\n",
        "            test_size=0.2, random_state=11, stratify=self.labels)\n",
        "        self.weights, self.weights_per_class = self.make_weights_for_balanced_classes(tr_labels)\n",
        "        tst_inputs, val_inputs, tst_masks, val_masks, tst_labels, val_labels, tst_imdb_ids, val_imdb_ids = train_test_split(\n",
        "            val_inputs, val_masks, val_labels, val_imdb_ids, \n",
        "            test_size=0.25, random_state=11)\n",
        "        classes_info = 'Train set: '+str(len(tr_inputs))+'\\nVal set: ' + str(len(val_inputs)) +'\\nTest set: '+str(len(tst_inputs))\n",
        "        with open('dataset_info.txt', 'w') as f:\n",
        "            f.write(classes_info)\n",
        "        mlflow.log_artifact('dataset_info.txt')\n",
        "\n",
        "        tr_inputs, tr_masks, tr_labels, tr_imdb_ids = self.prepare_tokenized_chunks_masks_labels(\n",
        "            tr_inputs, tr_masks, tr_labels, tr_imdb_ids)\n",
        "        val_inputs, val_masks, val_labels, val_imdb_ids = self.prepare_tokenized_chunks_masks_labels(\n",
        "            val_inputs, val_masks, val_labels, val_imdb_ids)\n",
        "        tst_inputs, tst_masks, tst_labels, tst_imdb_ids = self.prepare_tokenized_chunks_masks_labels(\n",
        "            tst_inputs, tst_masks, tst_labels, tst_imdb_ids)\n",
        "        \n",
        "        return tr_inputs, tr_masks, tr_labels, val_inputs, val_masks, val_labels, tst_inputs, tst_masks, tst_labels, tr_imdb_ids, val_imdb_ids, tst_imdb_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1tySQRSaYUe"
      },
      "source": [
        "def get_dataloader(input_ids, labels, attention_masks, imdb_ids, \n",
        "                   batch_size=1,  phase='train', sampler=None):\n",
        "        dataset = TensorDataset(input_ids, attention_masks, labels, imdb_ids)\n",
        "        if phase=='train':\n",
        "            sampler = sampler if not sampler is None else RandomSampler(dataset)\n",
        "            dataloader = DataLoader(\n",
        "                        dataset,  \n",
        "                        batch_size = batch_size,\n",
        "                        sampler = sampler,\n",
        "                        drop_last=True\n",
        "                    )\n",
        "        else:\n",
        "            dataloader = DataLoader(\n",
        "                        dataset,  \n",
        "                        batch_size = batch_size,\n",
        "                        drop_last=True\n",
        "                    )\n",
        "\n",
        "        return dataloader "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCnARWcEaaEr"
      },
      "source": [
        "def get_data_loaders():\n",
        "    SD = ScriptData(config, tokenizer)\n",
        "    #tr_inputs, val_inputs, tst_inputs, tr_labels, val_labels, tst_labels = AD.get_train_val_split()\n",
        "    tr_inputs, tr_masks, tr_labels, val_inputs, val_masks, val_labels, tst_inputs, tst_masks, tst_labels, tr_imdb_ids, val_imdb_ids, tst_imdb_ids = SD.get_train_val_split()\n",
        "    #tr_inputs, tr_attention_masks, tr_labels, val_inputs, val_attention_masks, \\\n",
        "    #val_labels, tst_inputs, tst_attention_masks, tst_labels = SD.get_train_val_split()\n",
        "\n",
        "    #tr_loader = get_dataloader(tr_inputs[[0, 1, 3, 4]], tr_labels[[0, 1, 3, 4]],  tr_attention_masks[[0, 1, 3, 4]], # [0, 1, 3, 4]\n",
        "    tr_loader = get_dataloader(tr_inputs, tr_labels,  tr_masks, tr_imdb_ids, \n",
        "                            batch_size=config['train']['tr_batch_size'],\n",
        "                            sampler = WeightedRandomSampler(SD.weights, len(SD.weights)))\n",
        "    val_loader = get_dataloader(val_inputs, val_labels,  val_masks, val_imdb_ids, \n",
        "                                batch_size=config['train']['tst_batch_size'])\n",
        "    tst_loader = get_dataloader(tst_inputs, tst_labels,  tst_masks, tst_imdb_ids,\n",
        "                                batch_size=config['train']['tst_batch_size'])\n",
        "    \n",
        "    return tr_loader, val_loader, tst_loader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJJyqEJQGtVh"
      },
      "source": [
        "### Additional x2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv0_iv7W8UAM"
      },
      "source": [
        "with open('/content/labels.pickle', 'rb') as f:\n",
        "    labels = pickle.load(f)\n",
        "with open('/content/labels_true.pickle', 'rb') as f:\n",
        "    labels_true = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKDmOqLy8eZT"
      },
      "source": [
        "print(labels[:20])\n",
        "print(labels_true[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-R6d8tZ8bwO"
      },
      "source": [
        "print(labels == labels_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrEp7xPV7RwR"
      },
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "SD = ScriptData(config, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52wlS-fFypE1"
      },
      "source": [
        "print(SD.classes_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGg2CD7EywUm"
      },
      "source": [
        "print(len(SD.classes_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8p3r211CpOO"
      },
      "source": [
        "print(len(SD.scripts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TifqejsW9HlW"
      },
      "source": [
        "print(dir(tokenizer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZHPR5DK9P8L"
      },
      "source": [
        "print(tokenizer.special_tokens_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERXFy1AyCM3J"
      },
      "source": [
        "tokenized_chunks_for_scripts, attention_masks = SD.make_tokenized_chunks_for_scripts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2WUvW_1BaHu"
      },
      "source": [
        "print(len(tokenized_chunks_for_scripts[0][0]))\n",
        "print(len(tokenized_chunks_for_scripts[0]))\n",
        "print(len(tokenized_chunks_for_scripts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr8xdxLrFifF"
      },
      "source": [
        "from itertools import chain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qu0QHT0FlFb"
      },
      "source": [
        "scrit_scenes = list(chain(*tokenized_chunks_for_scripts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58NLvgIyFqfW"
      },
      "source": [
        "print(len(scrit_scenes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGkcnaPgF9nT"
      },
      "source": [
        "print(len(scrit_scenes[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cdJek6gF56J"
      },
      "source": [
        "scene_lengths = [len(x) for x in scrit_scenes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pu3bbk9DRCx"
      },
      "source": [
        "script_scenes_count = [len(x) for x in tokenized_chunks_for_scripts]\n",
        "print(len(script_scenes_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rweow8E96VM"
      },
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "tr_inputs, tr_masks, tr_labels, val_inputs, val_masks, val_labels, tst_inputs, tst_masks, tst_labels, tr_imdb_ids, val_imdb_ids, tst_imdb_ids = SD.get_train_val_split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1icS7L0hKMFa"
      },
      "source": [
        "print(tr_labels[:20])\n",
        "print(tr_imdb_ids[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NErn0NmALAAq"
      },
      "source": [
        "print(len(tr_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ye4tOuAK22u"
      },
      "source": [
        "with open(os.path.join('/content/drive/MyDrive/Data for baseline/Awards', 'val_labels.pickle'), 'wb') as f:\n",
        "    pickle.dump(val_labels, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-Q7xqxOLNuC"
      },
      "source": [
        "with open(os.path.join('/content/drive/MyDrive/Data for baseline/Awards', 'tr_imdb_ids.pickle'), 'wb') as f:\n",
        "    pickle.dump(tr_imdb_ids, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzsFvFG5RRF4"
      },
      "source": [
        "print(tr_labels[:10])\n",
        "#print(tr_labels[[0, 1, 3, 4]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRBQ-DUb_hvW"
      },
      "source": [
        "print(tr_inputs.shape)\n",
        "print(tr_inputs[0].shape)\n",
        "print(tr_inputs[1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjm4tL-7RWa1"
      },
      "source": [
        "imdb_ids_to_labels = {'tr': dict(zip(tr_imdb_ids, tr_labels)), 'val':dict(zip(val_imdb_ids, val_labels)), 'tst':dict(zip(tst_imdb_ids, tst_labels))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk6LMrJnOeBf"
      },
      "source": [
        "print(tr_labels[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQuWZTdUPmS-"
      },
      "source": [
        "print(tr_inputs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0FZWcHQP5BJ"
      },
      "source": [
        "print(tr_inputs[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZR25rn3QCdQ"
      },
      "source": [
        "print(tokenizer.convert_ids_to_tokens(tr_inputs[3][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYCx7WY3QW6I"
      },
      "source": [
        "print(tokenizer.convert_ids_to_tokens(tr_inputs[3][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A3f5STxQfmJ"
      },
      "source": [
        "print(tokenizer.convert_ids_to_tokens(tr_inputs[3][2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Igp58xMB6SX"
      },
      "source": [
        "!cp '/content/tokenized_scripts.pickle' '/content/drive/MyDrive/NLP/Movie scripts dataset/BERT training data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvWqyqXwCN8_"
      },
      "source": [
        "with open('tokenized_scripts.pickle', 'rb') as f:\n",
        "    tokenized_scripts = pickle.load(f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRigGxBrCUyB"
      },
      "source": [
        "print(len(tokenized_scripts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPOLyLyDCnm_"
      },
      "source": [
        "print(len(tokenized_scripts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY8GQhlCUBwe"
      },
      "source": [
        "script_num = 2\n",
        "print(tokenized_scripts[script_num])\n",
        "print(tokenized_chunks_for_scripts[script_num])\n",
        "print(attention_masks[script_num])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmWkWq1CUFdl"
      },
      "source": [
        "print(len(tokenized_scripts[script_num]))\n",
        "print(len(tokenized_chunks_for_scripts[script_num]))\n",
        "for chunk in tokenized_chunks_for_scripts[script_num]:\n",
        "    print(len(chunk))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIz2C7YsGCzA"
      },
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "tr_loader, val_loader, tst_loader = get_data_loaders()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opmYFwrEX3Lv"
      },
      "source": [
        "!cp '/content/tokenized_script_chunks.pickle' '/content/drive/MyDrive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTTQvTAURnXc"
      },
      "source": [
        "with open('/content/attention_masks.pickle', 'rb') as f:\n",
        "    attention_1 = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEYyxJjmR1Fe"
      },
      "source": [
        "print(len(attention_1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI1gVgt9R4sO"
      },
      "source": [
        "print(attention_1[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFxVXpFGRt0i"
      },
      "source": [
        "with open('/content/drive/MyDrive/attention_masks.pickle', 'rb') as f:\n",
        "    attention_2 = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgmAbkcUR3JW"
      },
      "source": [
        "print(attention_2[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6Z2jzxzXuoA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcIAWKVkR_mN"
      },
      "source": [
        "print(attention_1==attention_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGJosv2kIR-d"
      },
      "source": [
        "for i, d in enumerate(tr_loader):\n",
        "    print(d)\n",
        "    print(d[0].shape)\n",
        "    print(d[1].shape)\n",
        "    print(d[2].shape)\n",
        "    print()\n",
        "    if i>5:\n",
        "        break "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wJsZhzZ30q6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMyxi6wL1WKP"
      },
      "source": [
        "ckpt = torch.load(config['paths']['ckpt_to_load'],\n",
        "                                       #'script_classification_with_val_checkpoint_val_0_5955'),\n",
        "                          map_location=config['train']['device'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxZo5j9y1ihj"
      },
      "source": [
        "print(ckpt.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMujH2Ed1piw"
      },
      "source": [
        "print(ckpt['model'].keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWm7BPGZ19pH"
      },
      "source": [
        "transformer_model = BertModel.from_pretrained(\n",
        "                config['train']['pretrained_model_type'],\n",
        "                gradient_checkpointing=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KkgiHos2TvE"
      },
      "source": [
        "print(list(transformer_model.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evRTV-sH2Bpv"
      },
      "source": [
        "print(transformer_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-et7ioyS9Ci"
      },
      "source": [
        "### Scripts length stats:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hETqm1ZDGoL7"
      },
      "source": [
        "print(max(scene_lengths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrzl7Zpm54Mo"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt \n",
        "\n",
        "#lengths = [len(x) for x in tokenized_scripts]\n",
        "lengths = scene_lengths\n",
        "bins = list([0,100,200,300,400, 512] + list(range(600,3000,200)) + [3000, 31688])\n",
        "h, bins = np.histogram(lengths, bins=bins)\n",
        "h_cum = np.cumsum(h)\n",
        "nrof_movies = np.sum(h)\n",
        "h_cum_to_show = [str(x)+ ':\\n'+str(round(float(x)/nrof_movies, 3)) for x in h_cum]\n",
        "file_path = os.path.join('/content/drive/MyDrive/NLP/Movie scripts dataset/BERT training data/scripts_scenes_lengths_distribution.png')\n",
        "#file_path = 'Scripts_scenes_count_distribution.png'\n",
        "bins = [str(bins[i])+'-'+str(bins[i+1])for i in range(len(bins)-1)]\n",
        "show_histogram(bins, h, figsize=(20,15), x_label='Number of tokens', values_to_show= h_cum_to_show, y_label='Number of scenes',\n",
        "               set_rotation=True, title='Scripts scenes lengths distribution', file_path=file_path,\n",
        "               dpi=200, to_save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "137MDHuSRx_5"
      },
      "source": [
        "## Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNf_-V1mV1GC"
      },
      "source": [
        "class TransformerQA(nn.Module):\n",
        "    def __init__(self, model, confg): \n",
        "        super(TransformerQA, self).__init__()\n",
        "        self.transformer_model = model\n",
        "        print('bert params:')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        #print(self.transformer_model.parameters())\n",
        "        for param in self.transformer_model.parameters():\n",
        "            param.requires_grad = True \n",
        "\n",
        "        #self.cls_ff = torch.nn.Linear(config['train']['embedding_size'], 2)\n",
        "        self.cls_ff = nn.Linear(config['train']['embedding_size'], config['train']['num_classes'])\n",
        "        #self.cls_ff = nn.Sequential(\n",
        "          #  nn.Dropout(0.1),\n",
        "           # nn.Linear(config['train']['embedding_size'], config['train']['num_classes'])\n",
        "         #   )\n",
        "        self.lstm = LSTM(config['train']['embedding_size'],config['train']['embedding_size'])\n",
        "        '''\n",
        "        self.cls_ff = nn.Sequential(\n",
        "            nn.Linear(config['train']['embedding_size'], 3072),\n",
        "            nn.Linear(3072, config['train']['embedding_size']),\n",
        "            nn.LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(config['train']['embedding_size'], config['train']['embedding_size']),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(config['train']['embedding_size'], config['train']['num_classes']),\n",
        "            #nn.Sigmoid()\n",
        "        )\n",
        "        '''\n",
        "\n",
        "    def forward(self, script, input_masks, label):\n",
        "        '''\n",
        "        script squeezed (of size (nrof chunks, max seq len))\n",
        "        '''\n",
        "        script_vector = []\n",
        "        bert_output = torch.zeros(config['train']['tr_batch_size'], \n",
        "                                  config['train']['max_scene_number'],\n",
        "                                  #config['train']['max_script_length'] // config['train']['max_seq_length'],\n",
        "                                  config['train']['embedding_size'],\n",
        "                                  device=config['train']['device'])\n",
        "        #for i, (name, param) in enumerate(self.transformer_model.named_parameters()):                \n",
        "         #   if param.requires_grad and name=='encoder.layer.11.output.dense.weight':\n",
        "          #      print(name)\n",
        "           #     print(param.data)\n",
        "            #    print()\n",
        "            \n",
        "        #print('ff weights', self.cls_ff.weight)\n",
        "        #print('script.shape', script.shape)\n",
        "        #### ?????!\n",
        "        #print('transformer_model params', list(self.transformer_model.parameters())[0][0])\n",
        "        for i in range(script.shape[1]):   \n",
        "            #outputs = self.dropout(self.transformer_model(script[:, i, :],\n",
        "                                 #attention_mask = input_masks[:, i, :][1])  \n",
        "            #print('BERT OUTPUTS')\n",
        "            #print(outputs)\n",
        "            #cls_vector = outputs['hidden_states'][0][:,0,:]\n",
        "            #print('cls shape', cls_vector.shape)\n",
        "            #bert_output[:, i, :] = cls_vector\n",
        "            #bert_output[:, i, :] = outputs[1] #self.dropout(\n",
        "            bert_output[:, i, :] = self.transformer_model(script[:, i, :],\n",
        "                                 attention_mask = input_masks[:, i, :]).last_hidden_state[:,0,:]\n",
        "            #script_vector.append(cls_vector)\n",
        "       \n",
        "        #stacked = torch.stack(script_vector)\n",
        "        script_vector = torch.mean(bert_output, 1)\n",
        "        #output, (_, _) = self.lstm(bert_output.permute(1,0,2))\n",
        "        #print('lstm output.shape', output.shape)\n",
        "        \n",
        "        #last_layer = self.dropout(F.relu(output[-1]))\n",
        "        #ff_res = self.cls_ff(last_layer)\n",
        "        #ff_res = self.cls_ff(output.permute(1,0,2))\n",
        "        \n",
        "\n",
        "        ff_res = self.cls_ff(self.dropout(F.relu(script_vector)))\n",
        "\n",
        "        return ff_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDEP7EQyWocv"
      },
      "source": [
        "## Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7oDR7x1C7U0"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "\n",
        "def plot_conf_matr(trues, predicts, file_path_prefix='tr_', title='Confusion matrix',\n",
        "                   nrof_classes=2,  classes_names=['not nominated', 'nominated']):\n",
        "    results = np.zeros((nrof_classes,nrof_classes))\n",
        "    for t, p in zip(trues, predicts):\n",
        "        results[t][p]+=1\n",
        "        \n",
        "    df_cm = pd.DataFrame(results.astype(np.int), index = classes_names,\n",
        "                  columns = classes_names)\n",
        "    plt.figure(figsize = (7,7))    \n",
        "    ax = sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "    ax.set(xlabel='predicted', ylabel='actual',title=title)\n",
        "    plt.savefig(file_path_prefix+'conf_matrix.png', bbox_inches='tight')\n",
        "    plt.close()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPVtA4VzWqKo"
      },
      "source": [
        "class Train():\n",
        "    def __init__(self, config):\n",
        "        self.config = config \n",
        "        transformer_model = BertModel.from_pretrained(\n",
        "                config['train']['pretrained_model_type'],\n",
        "                gradient_checkpointing=True) \n",
        "                #output_attentions = False, \n",
        "                #output_hidden_states = True, \n",
        "             #   gradient_checkpointing=False\n",
        "              #  )\n",
        "        #transformer_model = self.config['train']['model'].from_pretrained(\n",
        "         #       config['train']['pretrained_model_type'], \n",
        "          #      num_labels = self.config['train']['num_classes'],\n",
        "           #     output_attentions = False, \n",
        "            #    output_hidden_states = True, \n",
        "             #   gradient_checkpointing=False\n",
        "              #  )\n",
        "        self.model = TransformerQA(transformer_model, self.config)\n",
        "        \n",
        "        opt_config = self.config['train']['optim']['AdamW']\n",
        "        for key, val in opt_config.items():\n",
        "            mlflow.log_param(key, val)\n",
        "        mlflow.log_param('nrof_classes', self.config['train']['num_classes'])\n",
        "        #self.optimizer = Opt.SGD(self.model.parameters(), lr=.00001, momentum=0.9,\n",
        "         #                        nesterov=True)\n",
        "        #self.optimizer = Opt.RMSprop(self.model.parameters(), lr = .0001, alpha = 0.9)\n",
        "        #'''\n",
        "        self.optimizer = AdamW(self.model.parameters(),\n",
        "                  lr = opt_config['lr'], \n",
        "                  eps = opt_config['eps'], \n",
        "                  weight_decay=opt_config['weight_decay'],\n",
        "                )        \n",
        "        #'''\n",
        "        #self.total_steps = self.config['train']['nrof_steps']\n",
        "        self.scheduler = get_cosine_schedule_with_warmup(self.optimizer, \n",
        "                                            num_warmup_steps = 50, \n",
        "                                            num_training_steps = self.config['train']['nrof_steps_for_shed'])\n",
        "        self.crit = CrossEntropyLoss()\n",
        "        self.model.to(self.config['train']['device'])\n",
        "        #self.training_stats = []\n",
        "\n",
        "        self.global_step = 0\n",
        "\n",
        "        #mlflow.log_param('total_steps', self.total_steps)\n",
        "    \n",
        "    def save_model(self, step=None):\n",
        "        torch.save({\"model\": self.model.state_dict(),\n",
        "                    \"optimizer\": self.optimizer.state_dict(),\n",
        "                    \"scheduler\": self.scheduler.state_dict(),\n",
        "                    'global_step': self.global_step\n",
        "                    },\n",
        "                   os.path.join(self.config['paths']['ckpt_dir'], \n",
        "                                self.config['train']['exp_name'] + '_checkpoint' + ('_'+str(step) if step else '')))\n",
        "        print('Model saved...')\n",
        "    \n",
        "    def load_model(self):\n",
        "        if self.config['train']['use_intermediate_weights']:\n",
        "            ckpt = torch.load(self.config['paths']['ckpt_to_load'],\n",
        "                          map_location=self.config['train']['device'])\n",
        "            model_st_dict = ckpt[\"model\"]\n",
        "            model_st_dict = dict([(key.replace('bert', 'transformer_model'), value) for key, value in model_st_dict.items()])\n",
        "            self.model.load_state_dict(model_st_dict, strict=False)   \n",
        "        else:\n",
        "            ckpt = torch.load(self.config['paths']['ckpt_to_load'],\n",
        "            #ckpt = torch.load(os.path.join(self.config['paths']['ckpt_dir'],\n",
        "             #                           self.config['train']['exp_name'] + '_checkpoint'),\n",
        "                            map_location=self.config['train']['device'])\n",
        "            model_st_dict = ckpt[\"model\"]\n",
        "            self.model.load_state_dict(model_st_dict)   \n",
        "            self.global_step = ckpt[\"global_step\"] + 1\n",
        "            self.optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "            self.scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
        "        print(\"Model loaded...\")\n",
        "\n",
        "\n",
        "    def train(self, \n",
        "              train_dataloader, \n",
        "              validation_dataloader,\n",
        "              to_save=True):\n",
        "        if self.config['train']['load_model']:\n",
        "            self.load_model()\n",
        "        self.model.train()\n",
        "        print('GLOBAL STEP:', self.global_step)\n",
        "        t0 = time()\n",
        "\n",
        "        predicts, trues = [], []\n",
        "        tr_losses = []\n",
        "        cur_loss, nrof_steps, = 0., 0,\n",
        "        nrof_cor_predicts_current, nrof_cor_predicts =0, 0\n",
        "        nrof_samples_current, nrof_samples = 0, 0\n",
        "        print('Train loader len:', len(train_dataloader))\n",
        "        #class_correct = list(0. for i in range(self.config['train']['num_classes']))\n",
        "        #class_total = list(0. for i in range(self.config['train']['num_classes']))\n",
        "    \n",
        "        for epoch in tqdm(range(self.config['train']['nrof_epochs'])):\n",
        "            predicts, trues = [], []\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                if epoch * len(train_dataloader) + step < self.global_step:\n",
        "                    continue\n",
        "                print('epoch: {} step: {}'.format(epoch, step))\n",
        "                \n",
        "                b_input_ids = batch[0].to(self.config['train']['device'])\n",
        "                b_input_mask = batch[1].to(self.config['train']['device'])\n",
        "                b_labels = batch[2].to(self.config['train']['device'])       \n",
        "                \n",
        "                \n",
        "                self.model.zero_grad()  \n",
        "                try:\n",
        "                    output = self.model(b_input_ids, \n",
        "                                        b_input_mask, b_labels)\n",
        "                    #for param in self.model.parameters():\n",
        "                     #   print(param)\n",
        "                      #  break \n",
        "                        #param.requires_grad = False\n",
        "                    loss = self.crit(output, b_labels)\n",
        "                    cur_loss +=loss.item()\n",
        "                    tr_losses.append(loss.item())\n",
        "                    _, predicted = torch.max(output,-1)\n",
        "                    predicts.extend(predicted.cpu().detach().numpy().flatten().tolist())\n",
        "                    trues.extend(b_labels.cpu().detach().numpy().flatten().tolist())\n",
        "                    #for i, label in enumerate(b_labels.cpu().detach().numpy()):\n",
        "                     #   class_correct[int(label)] += (predicted == b_labels)[i].item()\n",
        "                      #  class_total[int(label)] += 1\n",
        "\n",
        "                    loss.backward()\n",
        "                    #torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "                    self.optimizer.step()\n",
        "                    self.scheduler.step()\n",
        "                    self.global_step+=1\n",
        "                    nrof_steps+=1\n",
        "                    nrof_samples+=len(b_labels)\n",
        "                except RuntimeError as excp:\n",
        "                    if \"out of memory\" in str(excp):\n",
        "                        print(\"Out of memory!\")\n",
        "                        if hasattr(torch.cuda,'empty_cache'): \n",
        "                            torch.cuda.empty_cache() \n",
        "                    else:\n",
        "                        raise excp\n",
        "                \n",
        "                if self.global_step % 1 == 0: \n",
        "                    elapsed = format_time(time() - t0) \n",
        "                    #if self.global_step % 10 == 0: \n",
        "                     #   self.save_model(step=self.global_step)\n",
        "                      #  files.download(os.path.join('/content/ckpts', self.config['train']['exp_name'] + '_checkpoint' + '_'+str(self.global_step))) \n",
        "\n",
        "                    '''\n",
        "                    if self.global_step % 20 == 0: \n",
        "                        try:\n",
        "                            avg_val_loss, val_trues, val_predicts = self.validate(validation_dataloader)\n",
        "                            avg_val_accuracy = balanced_accuracy_score(val_trues, val_predicts)\n",
        "                            mlflow.log_metric(\"val_loss\", avg_val_loss, step=self.global_step)\n",
        "                            mlflow.log_metric(\"val_accuracy\", avg_val_accuracy, step=self.global_step)\n",
        "                            #mlflow.log_metric(\"val_f1_score\", val_f1_score, step=self.global_step)\n",
        "                            print('val loss: {}\\nval bal accuracy: {}'.format(\n",
        "                                avg_val_loss,  avg_val_accuracy))\n",
        "                            plot_conf_matr(val_trues, val_predicts, title=str(self.global_step)+'_', \n",
        "                                           nrof_classes=self.config['train']['num_classes'], \n",
        "                                           classes_names=self.config['train']['classes_names'][self.config['train']['task_name']])\n",
        "                            mlflow.log_artifact(str(self.global_step)+'_conf_matrix.png')\n",
        "                            #self.model.train()\n",
        "                            #torch.cuda.empty_cache()\n",
        "                        except RuntimeError as excp:\n",
        "                            if \"out of memory\" in str(excp):\n",
        "                                print(\"Out of memory in VAL!\")\n",
        "                                if hasattr(torch.cuda,'empty_cache'): \n",
        "                                    torch.cuda.empty_cache() \n",
        "                            else:\n",
        "                                raise excp\n",
        "                    '''\n",
        "                    if nrof_steps!=0:\n",
        "                        tr_losses = tr_losses[-50:]\n",
        "                        trues, predicts = trues[-50:], predicts[-50:] \n",
        "                        bal_tr_accuracy = balanced_accuracy_score(trues, predicts)\n",
        "                        #tr_f1_score = f1_score(trues, predicts)\n",
        "                        mlflow.log_metric(\"train_loss\", cur_loss / nrof_steps, step=self.global_step) \n",
        "                        mlflow.log_metric(\"train_average_loss\", np.mean(tr_losses),  step=self.global_step)\n",
        "                        mlflow.log_metric(\"train_bal_accuracy\", bal_tr_accuracy, step=self.global_step)\n",
        "                        #mlflow.log_metric(\"train_f1_score\", tr_f1_score, step=self.global_step)\n",
        "                        if self.global_step % 5 == 0: \n",
        "                            print('Elapsed: {:}.'.format(elapsed))\n",
        "                            print('tr loss: {}\\ntr bal accuracy: {}'.format(cur_loss/nrof_steps, \n",
        "                                                                    bal_tr_accuracy))\n",
        "                            print('trues: {}\\npredicts:{}'.format(trues, predicts))\n",
        "                        \n",
        "                        cur_loss, nrof_steps = 0., 0\n",
        "                        #trues, predicts = [], []\n",
        "                    #val_acc,  val_classes_accs, val_loss =\\\n",
        "                    # self.validate(validation_dataloader)\n",
        "                    \n",
        "                    #print('val accs by classes:\\n', '\\n'.join(\n",
        "                        #   [self.config['train']['class_to_heading_map'][i]+': '+str(round(x, 3)) for i, x in enumerate(val_classes_accs)]))\n",
        "                    #print('val loss:', val_loss)\n",
        "                    \n",
        "                    #mlflow.log_metric(\"val_balanced_accuracy\", np.mean(val_classes_accs))\n",
        "                    \n",
        "                    #plot_conf_matr(class_correct, class_total)\n",
        "                    #mlflow.log_metric(\"train_loss\", cur_loss / nrof_steps)\n",
        "                    #tr_class_accs = np.asarray(class_correct) / np.asarray(class_total)\n",
        "                    #tr_bal_acc = np.mean(tr_class_accs)\n",
        "                    #tr_accuracy = balanced_accuracy_score(trues, predicts)\n",
        "                    #tr_f1_score = f1_score(trues, predicts)\n",
        "                    #mlflow.log_metric(\"train_accuracy\", tr_accuracy)\n",
        "                    #mlflow.log_metric(\"train_f1_score\", tr_f1_score)\n",
        "                    #mlflow.log_metric(\"train_accuracy_accum\", float(nrof_cor_predicts)/nrof_samples)\n",
        "                    \n",
        "                    #mlflow.log_metric(\"train_balanced_accuracy\", tr_bal_acc)\n",
        "                    #print('tr loss: {}\\ntr accuracy: {}'.format(cur_loss/nrof_steps, \n",
        "                     #                                           tr_accuracy))\n",
        "\n",
        "                    \n",
        "                    #predicts, trues = [], []\n",
        "\n",
        "                if self.global_step % 20 == 0: # 5\n",
        "                    self.save_model()\n",
        "                    try:\n",
        "                        copytree('/content/mlruns', self.config['paths']['mlruns'] + '_' + self.config['train']['exp_name'] +'_'+str(self.global_step))\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "                        pass \n",
        "                if self.global_step % 100 == 0: # 5\n",
        "                    self.save_model(step=self.global_step)\n",
        "\n",
        "                training_time = (time() - t0)\n",
        "            self.save_model(step=self.global_step)\n",
        "        \n",
        "        #self.save_model(step=self.global_step)\n",
        "            try:\n",
        "                copytree('/content/mlruns', self.config['paths']['mlruns'] + '_' + self.config['train']['exp_name'])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                pass \n",
        "            \n",
        "\n",
        "\n",
        "    def validate(self, validation_dataloader, to_load=False):\n",
        "        if to_load:\n",
        "            self.load_model()\n",
        "        t1 = time()\n",
        "        self.model.eval()\n",
        "        probs, predicts, trues, imdb_ids = [], [], [], []\n",
        "        nrof_steps, val_loss, nrof_cor_predicts, nrof_samples = 0, 0., 0, 0\n",
        "        \n",
        "        #class_correct = list(0. for i in range(self.config['train']['num_classes']))\n",
        "        #class_total = list(0. for i in range(self.config['train']['num_classes']))\n",
        "\n",
        "        for i, batch in tqdm(enumerate(validation_dataloader)):\n",
        "            with torch.no_grad(): \n",
        "                b_input_ids = batch[0].to(self.config['train']['device'])\n",
        "                b_input_mask = batch[1].to(self.config['train']['device'])\n",
        "                b_labels = batch[2].to(self.config['train']['device'])\n",
        "                b_imdb_ids = batch[3].to(self.config['train']['device'])       \n",
        "\n",
        "                output = self.model(b_input_ids, \n",
        "                                    b_input_mask, b_labels)\n",
        "                val_loss += self.crit(output, b_labels).item()\n",
        "                #_, predicted = torch.max(output,-1)\n",
        "                sig_probs, predicted = torch.max(output.sigmoid(),-1)\n",
        "                probs.extend(sig_probs.cpu().detach().numpy().flatten().tolist())\n",
        "                predicts.extend(predicted.cpu().detach().numpy().flatten().tolist())\n",
        "                trues.extend(b_labels.cpu().detach().numpy().flatten().tolist())\n",
        "                imdb_ids.extend(b_imdb_ids.cpu().detach().numpy().flatten().tolist())\n",
        "                #if_right = (predicted == b_labels).sum().item()\n",
        "                #nrof_cor_predicts += if_right\n",
        "                #for i, label in enumerate(b_labels.cpu().detach().numpy()):\n",
        "                 #   class_correct[int(label)] += (predicted == b_labels)[i].item()\n",
        "                  #  class_total[int(label)] += 1\n",
        "\n",
        "                '''\n",
        "                if_right = int(predicted == b_labels)\n",
        "                nrof_cor_predicts += if_right\n",
        "                #nrof_cor_predicts_current += if_right\n",
        "                class_correct[b_labels.item()] += if_right\n",
        "                class_total[b_labels.item()] += 1\n",
        "                '''\n",
        "                nrof_steps+=1\n",
        "                nrof_samples+=len(b_labels)\n",
        "                #nrof_samples_current+=len(b_labels)\n",
        "\n",
        "\n",
        "                '''\n",
        "                b_input_ids = batch[0].to(self.config['train']['device'])\n",
        "                #b_input_mask = batch[1].to(self.config['train']['device'])\n",
        "                b_labels = batch[1].to(self.config['train']['device'])\n",
        "                _,_, = self.model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            #attention_mask=b_input_mask,\n",
        "                            labels=b_labels,\n",
        "                            return_dict=True)\n",
        "                val_loss += outputs.loss.item()\n",
        "                _, predicted = torch.max(outputs.logits,-1)\n",
        "                c = (predicted == b_labels)\n",
        "                nrof_cor_predicts += c.sum().item()\n",
        "                for i in range(b_labels.size(0)):\n",
        "                    label = b_labels[i]\n",
        "                    if torch.is_tensor(label):\n",
        "                        for j, ll in enumerate(label):\n",
        "                            class_correct[ll] += c[i][j].squeeze().item()\n",
        "                            class_total[ll] += 1\n",
        "                    else:\n",
        "                        class_correct[label] += c[i].squeeze().item()\n",
        "                        class_total[label] += 1\n",
        "\n",
        "                nrof_samples += len(b_labels)\n",
        "                '''\n",
        "\n",
        "                \n",
        "        #avg_val_accuracy = balanced_accuracy_score(trues, predicts)\n",
        "        #val_f1_score = f1_score(trues, predicts)\n",
        "        \n",
        "        avg_val_loss = val_loss / nrof_steps\n",
        "        validation_time = (time() - t1)\n",
        "        \n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "        \n",
        "        return avg_val_loss, trues, predicts, imdb_ids, probs\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sgB2rYAGH4e"
      },
      "source": [
        "print(T.global_step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiOz7WhoO_U5"
      },
      "source": [
        "mlflow.end_run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxR01AaeOJi2"
      },
      "source": [
        "T = Train(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w2MHdGUPDX_"
      },
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "tr_loader, val_loader, tst_loader = get_data_loaders()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95eZSQWENv15"
      },
      "source": [
        "T = Train(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv18bnZWN4nB"
      },
      "source": [
        "avg_tst_loss, tst_trues, tst_predicts, tst_imdb_ids, tst_probs = T.validate(tst_loader, to_load=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFO6yJoCQhi7"
      },
      "source": [
        "print(balanced_accuracy_score(tst_trues, tst_predicts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsE6QaXyQMC3"
      },
      "source": [
        "print(len(tst_trues))\n",
        "print(tst_trues[0])\n",
        "print(len(tst_imdb_ids))\n",
        "print(tst_imdb_ids[0])\n",
        "print(len(tst_probs))\n",
        "print(tst_probs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvXBWTEvTz8d"
      },
      "source": [
        "# Most confident errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM8XXMLTk585"
      },
      "source": [
        "with open('tst_trues_genre_acc_0_31.pickle', 'rb') as f:\n",
        "    tst_trues = pickle.load(f)\n",
        "with open('tst_predicts_genre_acc_0_31.pickle', 'rb') as f:\n",
        "    tst_predicts = pickle.load(f)\n",
        "with open('tst_imdb_ids_genre_acc_0_31.pickle', 'rb') as f:\n",
        "    tst_imdb_ids = pickle.load(f)\n",
        "with open('tst_probs_genre_acc_0_31.pickle', 'rb') as f:\n",
        "    tst_probs = pickle.load(f)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxPnOv7fEbL5"
      },
      "source": [
        "with open('tst_trues_awards_acc_0_74.pickle', 'rb') as f:\n",
        "    tst_trues = pickle.load(f)\n",
        "with open('tst_predicts_awards_acc_0_74.pickle', 'rb') as f:\n",
        "    tst_predicts = pickle.load(f)\n",
        "with open('tst_imdb_ids_awards_acc_0_74.pickle', 'rb') as f:\n",
        "    tst_imdb_ids = pickle.load(f)\n",
        "with open('tst_probs_awards_acc_0_74.pickle', 'rb') as f:\n",
        "    tst_probs = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WDy8fMdTrJ3"
      },
      "source": [
        "print(tst_probs[:10])\n",
        "print(tst_trues[:10])\n",
        "print(tst_predicts[:10])\n",
        "print(tst_imdb_ids[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK-gL52vT3ai"
      },
      "source": [
        "sorted_inds = np.argsort(tst_probs)[::-1]\n",
        "print(sorted_inds[:10])\n",
        "print(np.asarray(tst_probs)[sorted_inds][:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fitGZWvUca9U"
      },
      "source": [
        "errors_mask = np.asarray(tst_trues)[sorted_inds] != np.asarray(tst_predicts)[sorted_inds]\n",
        "print(errors_mask[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxXkfyFKcrLa"
      },
      "source": [
        "print(errors_mask[:50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glJIxzY8Uq9C"
      },
      "source": [
        "sorted_inds = np.argsort(tst_probs)[::-1]\n",
        "print(sorted_inds[:10])\n",
        "print(np.asarray(tst_probs)[sorted_inds][:50])\n",
        "print(np.asarray(tst_trues)[sorted_inds][:50])\n",
        "print(np.asarray(tst_predicts)[sorted_inds][:50])\n",
        "print(np.asarray(tst_imdb_ids)[sorted_inds][:50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foynBuT-cy9Z"
      },
      "source": [
        "print(np.asarray(tst_probs)[sorted_inds][errors_mask][:50])\n",
        "print(np.asarray(tst_trues)[sorted_inds][errors_mask][:50])\n",
        "print(np.asarray(tst_predicts)[sorted_inds][errors_mask][:50])\n",
        "print(np.asarray(tst_imdb_ids)[sorted_inds][errors_mask][:50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp31Jg1_QdOR"
      },
      "source": [
        "with open('tst_trues_awards_acc_0_74.pickle', 'wb') as f:\n",
        "    pickle.dump(tst_trues, f)\n",
        "with open('tst_predicts_awards_acc_0_74.pickle', 'wb') as f:\n",
        "    pickle.dump(tst_predicts, f)\n",
        "with open('tst_imdb_ids_awards_acc_0_74.pickle', 'wb') as f:\n",
        "    pickle.dump(tst_imdb_ids, f)\n",
        "with open('tst_probs_awards_acc_0_74.pickle', 'wb') as f:\n",
        "    pickle.dump(tst_probs, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqvPDt8MFxMn"
      },
      "source": [
        "errors_df = pd.DataFrame({'movie':np.asarray(tst_imdb_ids)[sorted_inds][errors_mask].tolist(),\n",
        "             'true_class':np.asarray(tst_trues)[sorted_inds][errors_mask].tolist(),\n",
        "             'predicted_class':np.asarray(tst_predicts)[sorted_inds][errors_mask],\n",
        "             'predicted_proba':np.asarray(tst_probs)[sorted_inds][errors_mask]})\n",
        "errors_df.to_excel('genre_confident_errors.xlsx', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs83zoIIHh-J"
      },
      "source": [
        "errors_df = pd.DataFrame({'movie':np.asarray(tst_imdb_ids)[sorted_inds][errors_mask].tolist(),\n",
        "             'true_class':np.asarray(tst_trues)[sorted_inds][errors_mask].tolist(),\n",
        "             'predicted_class':np.asarray(tst_predicts)[sorted_inds][errors_mask],\n",
        "             'predicted_proba':np.asarray(tst_probs)[sorted_inds][errors_mask]})\n",
        "errors_df.to_excel('awards_confident_errors.xlsx', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Lac7y4Xeu22"
      },
      "source": [
        "!cp -r '/content/drive/MyDrive/NLP/Movie scripts models/BERTAssess/mlruns_script_awards_classification_10_scenes_average_with_nsp' ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geMeb9ceGuMo"
      },
      "source": [
        "with mlflow.start_run(run_name=config['train']['exp_name'], run_id='cfbe31a258a846bfb7953f1d224aa530'):\n",
        "    #'''\n",
        "    avg_tst_loss, tst_trues, tst_predicts = T.validate(tst_loader, to_load=True)\n",
        "    avg_tst_accuracy = balanced_accuracy_score(tst_trues, tst_predicts)\n",
        "    tst_f1_score = f1_score(tst_trues, tst_predicts)\n",
        "    plot_conf_matr(tst_trues, tst_predicts, \n",
        "                   file_path_prefix='test_steps_', title='Confusion matrix\\nbalanced accuracy: {:.2f}\\nf1 score: {:.2f}'.format(\n",
        "                       avg_tst_accuracy, tst_f1_score))\n",
        "    #'''\n",
        "    mlflow.log_artifact('test_steps_conf_matrix.png')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUwxv9U2KdgH"
      },
      "source": [
        "with mlflow.start_run(run_name=config['train']['exp_name'], run_id='cfbe31a258a846bfb7953f1d224aa530'):\n",
        "    '''\n",
        "    avg_tr_loss, tr_trues, tr_predicts = T.validate(tr_loader, to_load=True)\n",
        "    avg_tr_accuracy = balanced_accuracy_score(tr_trues, tr_predicts)\n",
        "    tr_f1_score = f1_score(tr_trues, tr_predicts)\n",
        "    plot_conf_matr(tr_trues, tr_predicts, \n",
        "                   file_path_prefix='train_steps_', title='Confusion matrix\\nbalanced accuracy: {:.2f}\\nf1 score: {:.2f}'.format(\n",
        "                       avg_tr_accuracy, tr_f1_score))\n",
        "    '''\n",
        "    mlflow.log_artifact('train_conf_matrix.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0rwVxoCJbu6"
      },
      "source": [
        "copytree('/content/mlruns', config['paths']['mlruns'] + '_' + config['train']['exp_name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma4N0S8QfAo6"
      },
      "source": [
        "shutil.rmtree('/content/mlruns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzGdMyDOMd8b"
      },
      "source": [
        "###################  !!!!!! ####################\n",
        "\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "with mlflow.start_run(run_name=config['train']['exp_name']):\n",
        "    tr_loader, val_loader, tst_loader = get_data_loaders()\n",
        "    T = Train(config)\n",
        "    T.train(tr_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mLPCoQWDrhd"
      },
      "source": [
        "mlflow.end_run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnGL3j_yQEln"
      },
      "source": [
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym7dPVfDcBNa"
      },
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree('/content/mlruns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY2EFh8QnDEt"
      },
      "source": [
        "shutil.rmtree('/content/mlruns/0/52b570918d414f40910adc950ebeeb31')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psw53nbG_-jm"
      },
      "source": [
        "avg_val_loss, trues, predicts = T.validate(tst_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq2RNkwE6RqU"
      },
      "source": [
        "avg_tr_loss, tr_trues, tr_predicts = T.validate(tr_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X__1GOlE8upw"
      },
      "source": [
        "avg_tr_accuracy = balanced_accuracy_score(tr_trues, tr_predicts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4obrMl6r8xjm"
      },
      "source": [
        "print(avg_tr_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaDnUMC6Es-p"
      },
      "source": [
        "avg_val_accuracy = balanced_accuracy_score(trues, predicts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY0A-LY9EvTm"
      },
      "source": [
        "print(avg_val_loss)\n",
        "print(avg_val_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CF8W8XGSAbH"
      },
      "source": [
        "import mlflow\n",
        "from pyngrok import ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbkBylrkDAOt"
      },
      "source": [
        "!cp -r '/content/drive/MyDrive/NLP/Movie scripts models/BERTAssess/mlruns_script_classification_with_val_765' ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-_Z93z7-zVf"
      },
      "source": [
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\") # run tracking UI in the background\n",
        "NGROK_AUTH_TOKEN = \"\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CusZpFa_VZ57"
      },
      "source": [
        "ngrok.kill()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvJYuI52Evw1"
      },
      "source": [
        "# BoW model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqrV4MWjaLuw"
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import svm\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tULksxdKwyeq"
      },
      "source": [
        "imdb_ids_to_labels = {'tr': dict(zip(tr_imdb_ids, tr_labels)), 'val':dict(zip(val_imdb_ids, val_labels)), 'tst':dict(zip(tst_imdb_ids, tst_labels))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkXrrPhzE2rT"
      },
      "source": [
        "def get_train_test_split(tr_imdb_ids, val_imdb_ids, tst_imdb_ids, path_to_script_lemmas):\n",
        "    processed_texts = []\n",
        "    train_inds, val_inds, test_inds = [], [], []\n",
        "    train_labels, val_labels, test_labels = [], [], []\n",
        "\n",
        "    i = 0\n",
        "    for file_name in tqdm(os.listdir(path_to_script_lemmas)):\n",
        "        imdb_id = file_name.split('_')[1]\n",
        "        with open(os.path.join(path_to_script_lemmas, file_name), 'r') as f:\n",
        "            text = f.read()\n",
        "        processed_texts.append(text)\n",
        "        if imdb_id in tr_imdb_ids:\n",
        "            train_inds.append(i)\n",
        "            train_labels.append(imdb_ids_to_labels['tr'][imdb_id].item())\n",
        "        elif imdb_id in val_imdb_ids:\n",
        "            val_inds.append(i)\n",
        "            val_labels.append(imdb_ids_to_labels['val'][imdb_id].item())\n",
        "        elif imdb_id in tst_imdb_ids:\n",
        "            test_inds.append(i)\n",
        "            test_labels.append(imdb_ids_to_labels['tst'][imdb_id].item())\n",
        "        i+=1\n",
        "    return processed_texts, train_inds, val_inds, test_inds, train_labels, val_labels, test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNBqHxNQE4v8"
      },
      "source": [
        "processed_texts, train_inds, val_inds, test_inds, train_labels, val_labels, test_labels = get_train_test_split(tr_imdb_ids, val_imdb_ids, tst_imdb_ids, config['paths']['script_lemmas'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QpmmXynaPeU"
      },
      "source": [
        "print(train_inds[:20])\n",
        "print(train_labels[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMVPQZ9ZE5y9"
      },
      "source": [
        "results_df = {'max_features':[], 'binary':[],'norm':[],'use_idf':[], 'smooth_idf':[],'sublinear_tf':[], 'Train balanced accuracy': [], 'Test balanced accuracy':[], 'Test f1-score':[]}\n",
        "#y = DP.labels # old dataset!!\n",
        "#y = processed_labels\n",
        "nrof_exps = 0\n",
        "for max_features in (1500, 2000):\n",
        "    for binary in (False, True):\n",
        "        for norm in ('l1', 'l2'):\n",
        "            for sublinear_tf in (False, True):\n",
        "                for use_idf in (False, True):\n",
        "                    if use_idf:\n",
        "                        for smooth_idf in (False, True):\n",
        "                            tfidfconverter = TfidfVectorizer(max_features=max_features, min_df=5, max_df=0.7, stop_words=stopwords.words('english'),\n",
        "                                                            binary=binary,norm=norm,use_idf=use_idf,smooth_idf=smooth_idf,sublinear_tf=sublinear_tf)\n",
        "                            X = tfidfconverter.fit_transform(processed_texts).toarray()\n",
        "                            X_train = X[train_inds]\n",
        "                            X_val = X[val_inds]\n",
        "                            X_test = X[test_inds]\n",
        "                            y_train = train_labels\n",
        "                            y_val = val_labels\n",
        "                            y_test = test_labels\n",
        "                            #X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=11)\n",
        "                            #X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=11)\n",
        "                            clf = svm.LinearSVC(class_weight='balanced', random_state=11)\n",
        "                            clf.fit(X_train, y_train)\n",
        "                            #clf = MLPClassifier(random_state=11, max_iter=10, hidden_layer_sizes =[2500, 2000, 1000, 500, 100], verbose=True).fit(X_train, y_train)\n",
        "                            y_pred = clf.predict(X_test)\n",
        "                            tr_y_pred = clf.predict(X_train)\n",
        "                            bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "                            tr_bal_acc = balanced_accuracy_score(y_train,tr_y_pred)\n",
        "                            #f1score = f1_score(y_test,y_pred)\n",
        "                            #print(balanced_accuracy_score(y_test,y_pred))\n",
        "                            #print(f1_score(y_test,y_pred))\n",
        "                            results_df['max_features'].append(max_features)\n",
        "                            results_df['binary'].append(binary)\n",
        "                            results_df['norm'].append(norm)\n",
        "                            results_df['use_idf'].append(use_idf)\n",
        "                            results_df['smooth_idf'].append(use_idf)\n",
        "                            results_df['sublinear_tf'].append(sublinear_tf)\n",
        "                            results_df['Train balanced accuracy'].append(round(tr_bal_acc, 4))\n",
        "                            results_df['Test balanced accuracy'].append(round(bal_acc, 4))\n",
        "                            #results_df['Test f1-score'].append(round(f1score, 4))\n",
        "                            results_df['Test f1-score'].append(0)\n",
        "                            #plot_conf_matr(y_test,y_pred, classes_names=['minor', 'main'], title=)\n",
        "                            #results_df['SVM linear results'].append('Train balanced accuracy: {:.4f}\\nTest balanced accuracy: {:.4f}\\nTest f1-score: {:.4f}'.format(tr_bal_acc, bal_acc, f1score))\n",
        "                            nrof_exps+=1\n",
        "                            print('nrof exps', nrof_exps)\n",
        "                    else:\n",
        "                        tfidfconverter = TfidfVectorizer(max_features=max_features, min_df=5, max_df=0.7, stop_words=stopwords.words('english'),\n",
        "                                                            binary=binary,norm=norm,use_idf=use_idf,sublinear_tf=sublinear_tf)\n",
        "                        X = tfidfconverter.fit_transform(processed_texts).toarray()\n",
        "                        X_train = X[train_inds]\n",
        "                        X_val = X[val_inds]\n",
        "                        X_test = X[test_inds]\n",
        "                        y_train = train_labels\n",
        "                        y_val = val_labels\n",
        "                        y_test = test_labels\n",
        "                        clf = svm.LinearSVC(class_weight='balanced', random_state=11)\n",
        "                        clf.fit(X_train, y_train)\n",
        "                        #clf = MLPClassifier(random_state=11, max_iter=10, hidden_layer_sizes =[2500, 2000, 1000, 500, 100], verbose=True).fit(X_train, y_train)\n",
        "                        y_pred = clf.predict(X_test)\n",
        "                        tr_y_pred = clf.predict(X_train)\n",
        "                        bal_acc = balanced_accuracy_score(y_test,y_pred)\n",
        "                        tr_bal_acc = balanced_accuracy_score(y_train,tr_y_pred)\n",
        "                        #f1score = f1_score(y_test,y_pred)\n",
        "                        #print(balanced_accuracy_score(y_test,y_pred))\n",
        "                        #print(f1_score(y_test,y_pred))\n",
        "                        results_df['max_features'].append(max_features)\n",
        "                        results_df['binary'].append(binary)\n",
        "                        results_df['norm'].append(norm)\n",
        "                        results_df['use_idf'].append(use_idf)\n",
        "                        results_df['smooth_idf'].append(False)\n",
        "                        results_df['sublinear_tf'].append(sublinear_tf)\n",
        "                        results_df['Train balanced accuracy'].append(round(tr_bal_acc, 4))\n",
        "                        results_df['Test balanced accuracy'].append(round(bal_acc, 4))\n",
        "                        #results_df['Test f1-score'].append(round(f1score, 4))\n",
        "                        results_df['Test f1-score'].append(0)\n",
        "                        #results_df['SVM linear results'].append('Train balanced accuracy: {:.4f}\\nTest balanced accuracy: {:.4f}\\nTest f1-score: {:.4f}'.format(tr_bal_acc, bal_acc, f1score))\n",
        "                        nrof_exps+=1\n",
        "                        print('nrof exps', nrof_exps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UriGJiu_m5pi"
      },
      "source": [
        "results_df = pd.DataFrame(results_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kKwa3ZYFHq8"
      },
      "source": [
        "results_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtcIUy4sm8kR"
      },
      "source": [
        "results_df.to_excel('BoW_validation_results_script_awards_new.xlsx', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVZdoDccm6kY"
      },
      "source": [
        "results_df.sort_values(by=['Test f1-score'], ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBgCMy5-n4am"
      },
      "source": [
        "tfidfconverter = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.7, stop_words=stopwords.words('english'),\n",
        "                                                            binary=False,norm='l2',use_idf=False,smooth_idf=False,sublinear_tf=True)\n",
        "X = tfidfconverter.fit_transform(processed_texts).toarray()\n",
        "X_train = X[train_inds]\n",
        "X_val = X[val_inds]\n",
        "X_test = X[test_inds]\n",
        "y_train = train_labels\n",
        "y_val = val_labels\n",
        "y_test = test_labels\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=11)\n",
        "#X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=11)\n",
        "clf = svm.LinearSVC(class_weight='balanced', random_state=11)\n",
        "clf.fit(X_train, y_train)\n",
        "#clf = MLPClassifier(random_state=11, max_iter=10, hidden_layer_sizes =[2500, 2000, 1000, 500, 100], verbose=True).fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "tr_y_pred = clf.predict(X_train)\n",
        "bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "tr_bal_acc = balanced_accuracy_score(y_train,tr_y_pred)\n",
        "#f1score = f1_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTXMdgO_pRQk"
      },
      "source": [
        "print(len(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmmyU9Y8pfr4"
      },
      "source": [
        "print(y_test[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ybswWNxpcuO"
      },
      "source": [
        "print(len(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJT0WtX_pitb"
      },
      "source": [
        "print(y_pred[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1b1tETLoxRu"
      },
      "source": [
        "plot_conf_matr(y_test, y_pred, title='Confusion matrix\\nBalanced accuracy: {}'.format(bal_acc), file_path_prefix='test_',\n",
        "               nrof_classes = config['train']['num_classes'],  classes_names=config['train']['classes_names'][config['train']['task_name']])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}