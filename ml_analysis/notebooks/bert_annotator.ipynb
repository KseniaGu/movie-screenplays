{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTAnnotator.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "c9tSHjflJYTV"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_kOHwQ2J5vu"
      },
      "source": [
        "# Screenplay annotation task (token- or row-wise). Labels:\n",
        "\n",
        "- scene_heading (0)\n",
        "- text (1)\n",
        "- speaker_heading (2)\n",
        "- dialog (3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training setup:"
      ],
      "metadata": {
        "id": "ge2__p9KT6Ga"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqeWsPfRoqM-"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCKptR8qJLFP"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install mlflow --quiet\n",
        "!pip install pyngrok --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHcDZXjuPi8-"
      },
      "source": [
        "import os\n",
        "import re\n",
        "from time import time \n",
        "from transformers import BertTokenizer, get_cosine_schedule_with_warmup\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, \\\n",
        "DistilBertForSequenceClassification,get_linear_schedule_with_warmup,\\\n",
        "BertForTokenClassification\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from matplotlib import pyplot as plt \n",
        "import seaborn as sn\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from itertools import chain\n",
        "import torch\n",
        "import numpy as np\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import csv\n",
        "import argparse\n",
        "import mlflow\n",
        "from pyngrok import ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t25UnTB8Bna"
      },
      "source": [
        "config = { \n",
        "        'paths': { \n",
        "            'logs_dir':'/content/drive/MyDrive/NLP/Movie scripts models/BERTAnno/logs',\n",
        "            'ckpt_dir': '/content/drive/MyDrive/NLP/Movie scripts models/BERTAnno/ckpts',\n",
        "            'model_annotations': '/content/drive/MyDrive/NLP/Movie scripts dataset/Movie scripts and annotations/Script annotations by BERT',\n",
        "            'manual_annotations': '/content/drive/MyDrive/NLP/Movie scripts dataset/Movie scripts and annotations/Script manual annotations',\n",
        "            'mlruns': '/content/drive/MyDrive/NLP/Movie scripts models/BERTAnno/mlruns'\n",
        "        },\n",
        "        'train': {\n",
        "                'optim' : {\n",
        "                    'AdamW':{\n",
        "                        'lr':1e-5,\n",
        "                        'eps': 1e-8,\n",
        "                        'weight_decay':0.0001\n",
        "                    }\n",
        "                },\n",
        "                'num_classes' : 4,\n",
        "                'nrof_steps' : 500, \n",
        "                'tr_batch_size' : 8,\n",
        "                'tst_batch_size' : 8,\n",
        "                'exp_name':'row_classification', # from ['row_classification', 'token_classification']\n",
        "                'device': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "                'pretrained_model_type': 'bert-base-cased',\n",
        "                'heading_to_class_map': {'scene_heading':0, 'text':1, 'speaker_heading':2, 'dialog':3},\n",
        "                'class_to_heading_map': {0:'scene_heading', 1:'text', 2:'speaker_heading', 3:'dialog'}\n",
        "                }\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsdAXApxpb7V"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    config['train']['pretrained_model_type'], do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKRKvTXdIl6H"
      },
      "source": [
        "\n",
        "## Dataset preprocesing:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHEBUYWIkwAG"
      },
      "source": [
        "def make_tokenized_rows(rows, tokenizer):\n",
        "    input_ids = []\n",
        "\n",
        "    for row in rows:\n",
        "        input_ids.append(tokenizer.encode(row))\n",
        "\n",
        "    return input_ids\n",
        "\n",
        "def make_tokenized_chunks_labels_from_rows(rows, labels, tokenizer, \n",
        "                                           chunk_size=512):\n",
        "    chunks_ids, new_labels = [[]], [[]]\n",
        "\n",
        "    for i, (row, label) in enumerate(zip(rows, labels)):\n",
        "        row_input_ids = tokenizer.encode(row)\n",
        "        \n",
        "        row_labels = [label] * len(row_input_ids)\n",
        "    \n",
        "        if (len(chunks_ids[-1]) + len(row_input_ids)) < chunk_size:\n",
        "            chunks_ids[-1].extend(row_input_ids)\n",
        "            new_labels[-1].extend(row_labels)\n",
        "        else:\n",
        "            chunks_ids.append(row_input_ids)\n",
        "            new_labels.append(row_labels)\n",
        "    \n",
        "    return chunks_ids, new_labels  \n",
        "\n",
        "def prepare_inputs_labels(inputs, labels):\n",
        "    inputs = [torch.tensor(input) for input in inputs]\n",
        "    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
        "    if config['train']['exp_name'] == 'row_classification':\n",
        "        labels = torch.LongTensor(labels)\n",
        "    else:\n",
        "        labels = [torch.tensor(label) for label in labels]\n",
        "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True) \n",
        "    return inputs, labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1n3O5NXIsVW"
      },
      "source": [
        "class AnnoData:\n",
        "    '''\n",
        "    Reads and prepares annotations\n",
        "    '''\n",
        "    def __init__(self, tokenizer, config):\n",
        "        self.config = config \n",
        "        anno_docs = self.read_all_annos()\n",
        "        self.labeled_rows, self.init_rows = self.make_labeled_rows(anno_docs)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def read_all_annos(self):\n",
        "        anno_docs = []\n",
        "        manual_annotations_path = self.config['paths']['manual_annotations']\n",
        "\n",
        "        for anno in os.listdir(manual_annotations_path):\n",
        "            with open(os.path.join(manual_annotations_path, anno), 'r') as f:\n",
        "                anno_text = f.read()\n",
        "                anno_docs.append(anno_text)\n",
        "\n",
        "        return anno_docs\n",
        "\n",
        "    def make_labeled_rows(self, anno_docs):\n",
        "        '''\n",
        "        Gets labeled rows from docs (removes existing label from string and gathers it to labels separately)\n",
        "        **** Fixed, but not used ****\n",
        "        '''\n",
        "        labeled_rows, init_rows = [], []\n",
        "        heading_to_class_map = self.config['train']['heading_to_class_map']\n",
        "\n",
        "        for anno_text in anno_docs:\n",
        "            anno_text = re.sub('\\n+','\\n', anno_text)\n",
        "            anno_text_splited = anno_text.split('\\n')\n",
        "            for row in anno_text_splited:\n",
        "                init_rows.append(row)\n",
        "                row_begin = row[:row.find(':')]\n",
        "                if row_begin in heading_to_class_map:\n",
        "                    label = heading_to_class_map[row_begin]\n",
        "                row = row.replace(row_begin + ':', '')\n",
        "                row = re.sub(' +',' ', row)\n",
        "                row = re.sub('\\t','', row).strip()\n",
        "                labeled_rows.append((row, label))\n",
        "\n",
        "        return labeled_rows, init_rows\n",
        "\n",
        "    def get_inputs_labels(self):\n",
        "        rows, labels = zip(*self.labeled_rows)\n",
        "        if self.config['train']['exp_name'] == 'row_classification':\n",
        "            return make_tokenized_rows(rows, self.tokenizer), labels\n",
        "        else:\n",
        "            return make_tokenized_chunks_labels_from_rows(rows, labels, self.tokenizer)\n",
        "\n",
        "    def get_train_val_split(self):\n",
        "        inputs, labels = self.get_inputs_labels()\n",
        "        tr_inputs, val_inputs, tr_labels, val_labels = train_test_split(inputs, labels,\n",
        "                                                                     test_size=0.3,\n",
        "                                                                     random_state=11)\n",
        "\n",
        "        if self.config['train']['exp_name'] == 'row_classification':\n",
        "            self.row_weights, self.weight_per_class = self.make_weights_for_balanced_classes(\n",
        "                tr_labels)\n",
        "        else:\n",
        "            self.row_weights, self.weight_per_class = None, None\n",
        "\n",
        "        if self.config['train']['exp_name'] == 'row_classification':\n",
        "            self.log_dataset_info() \n",
        "\n",
        "        tst_inputs, val_inputs, tst_labels, val_labels = train_test_split(\n",
        "            val_inputs, val_labels, test_size=0.5, random_state=11)\n",
        "        print('Train size:{}\\nVal size:{}\\nTest size:{}'.format(\n",
        "            len(tr_inputs), len(val_inputs), len(tst_inputs)))\n",
        "        \n",
        "        mlflow.log_param('train_size', len(tr_inputs))\n",
        "        mlflow.log_param('val_size', len(val_inputs))\n",
        "        mlflow.log_param('test_size', len(tst_inputs))\n",
        "\n",
        "        tr_inputs, tr_labels = prepare_inputs_labels(tr_inputs, tr_labels)\n",
        "        val_inputs, val_labels = prepare_inputs_labels(val_inputs, val_labels)\n",
        "        tst_inputs, tst_labels = prepare_inputs_labels(tst_inputs, tst_labels)\n",
        "        \n",
        "        return tr_inputs, val_inputs, tst_inputs, tr_labels, val_labels, tst_labels\n",
        "\n",
        "    def make_weights_for_balanced_classes(self, labels):     \n",
        "        nclasses = self.config['train']['num_classes']\n",
        "        count = [0] * nclasses\n",
        "\n",
        "        for label in labels:                                                         \n",
        "            count[label] += 1                                                     \n",
        "        weight_per_class = [0.] * nclasses       \n",
        "\n",
        "        N = float(sum(count))                                                   \n",
        "        for i in range(nclasses):                                                   \n",
        "            weight_per_class[i] = N/float(count[i])                                 \n",
        "        weight = [0] * len(labels)                                              \n",
        "        for idx, label in enumerate(labels):                                          \n",
        "            weight[idx] = weight_per_class[label]\n",
        "\n",
        "        return weight, weight_per_class \n",
        "    \n",
        "    def log_dataset_info(self):\n",
        "        print('Classes distribution:')\n",
        "        classes_info = []\n",
        "\n",
        "        for i, weight in enumerate(self.weight_per_class):\n",
        "            info_str = 'Class {}: {:.2f} of all rows'.format(\n",
        "                self.config['train']['class_to_heading_map'][i], 1./weight)\n",
        "            print(info_str)\n",
        "            classes_info.append(info_str)\n",
        "\n",
        "        classes_info = '\\n'.join(classes_info)\n",
        "\n",
        "        with open('classes_info.txt', 'w') as f:\n",
        "            f.write(classes_info)\n",
        "\n",
        "        mlflow.log_artifact('classes_info.txt')\n",
        "\n",
        "    def show_dataset(self, to_save=False):\n",
        "        dataset_df = {'label':[], 'class':[], 'tokens':[], 'text':[]}\n",
        "        inputs, labels = self.get_inputs_labels()\n",
        "\n",
        "        for input, label in zip(inputs, labels):\n",
        "            text = self.tokenizer.convert_ids_to_tokens(input)\n",
        "            string = self.tokenizer.convert_tokens_to_string(text)\n",
        "            dataset_df['class'].append(label)\n",
        "\n",
        "            if isinstance(label, list)\n",
        "                heading =  self.config['train']['class_to_heading_map'][label[0]]\n",
        "            else:\n",
        "                heading =  self.config['train']['class_to_heading_map'][label]\n",
        "\n",
        "            dataset_df['label'].append(heading)\n",
        "            dataset_df['tokens'].append(text)\n",
        "            dataset_df['text'].append(string)\n",
        "            \n",
        "        dataset_df = pd.DataFrame(dataset_df) \n",
        "        \n",
        "        if to_save:\n",
        "            dataset_df.to_excel('manual_annotations_dataset_' + self.data_type+'.xlsx', \n",
        "                                engine='xlsxwriter',\n",
        "                                index=False)       \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW8YF0inJvpc"
      },
      "source": [
        "def get_dataloader(input_ids, labels, batch_size=32,  #attention_masks\n",
        "                   phase='train', sampler=None):\n",
        "        dataset = TensorDataset(input_ids, labels)\n",
        "        if phase=='train':\n",
        "            sampler = sampler if not sampler is None else RandomSampler(dataset)\n",
        "            dataloader = DataLoader(\n",
        "                        dataset,  \n",
        "                        batch_size = batch_size,\n",
        "                        sampler = sampler \n",
        "                    )\n",
        "        else:\n",
        "            dataloader = DataLoader(\n",
        "                        dataset,  \n",
        "                        batch_size = 128 \n",
        "                    )\n",
        "\n",
        "        return dataloader "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtfMe9c8brh-"
      },
      "source": [
        "def get_data_loaders():\n",
        "    AD = AnnoData(tokenizer, config)\n",
        "    tr_inputs, val_inputs, tst_inputs, tr_labels, val_labels, tst_labels = AD.get_train_val_split()\n",
        "\n",
        "    if config['train']['exp_name'] == 'row_classification':\n",
        "        sampler = WeightedRandomSampler(AD.row_weights, len(AD.row_weights))      \n",
        "    else:\n",
        "        sampler = None \n",
        "\n",
        "    tr_loader = get_dataloader(tr_inputs, tr_labels, # tr_attention_masks\n",
        "                            batch_size=config['train']['tr_batch_size'],\n",
        "                            sampler=sampler)\n",
        "    val_loader = get_dataloader(val_inputs, val_labels, # val_attention_masks\n",
        "                                batch_size=config['train']['tst_batch_size'])\n",
        "    tst_loader = get_dataloader(tst_inputs, tst_labels, # tst_attention_masks\n",
        "                                batch_size=config['train']['tst_batch_size'])\n",
        "    \n",
        "    return tr_loader, val_loader, tst_loader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9tSHjflJYTV"
      },
      "source": [
        "## Show and save dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6mebB9070YR"
      },
      "source": [
        "!pip install xlsxwriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlSTKgF87Oui"
      },
      "source": [
        "AD = AnnoData(tokenizer, config, data_type='chunks')\n",
        "AD.show_dataset(to_save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PeZGm0rwRT_"
      },
      "source": [
        "AD = AnnoData(tokenizer, config)\n",
        "AD.show_dataset(to_save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3EYTFlXIssq"
      },
      "source": [
        "## Train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpWelL-7-qRb"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def prepare_row(row):\n",
        "    encoded_dict = tokenizer.encode_plus(row,                     \n",
        "                                         add_special_tokens = True, \n",
        "                                         max_length = 64,           \n",
        "                                         pad_to_max_length = True,\n",
        "                                         return_attention_mask = True,  \n",
        "                                         return_tensors = 'pt')\n",
        "    \n",
        "    input_ids=[encoded_dict['input_ids']]\n",
        "    attention_masks=[encoded_dict['attention_mask']]\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "def plot_conf_matr(results):\n",
        "    classes = [config['train']['class_to_heading_map'][x] for x in range(len(results))]\n",
        "    df_cm = pd.DataFrame(results.astype(np.int), index = classes, columns = classes)\n",
        "    plt.figure(figsize = (7,7))    \n",
        "    ax = sn.heatmap(df_cm, annot=True, fmt='d')\n",
        "    ax.set_title('Confusion matrix (test accuracy: {:.2f})'.format(\n",
        "        float(np.diagonal(results).sum()) / results.sum()))\n",
        "    plt.savefig('conf_matrix.png', bbox_inches='tight')\n",
        "    plt.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w33OWYzso1Qn"
      },
      "source": [
        "class Train():\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        if self.config['train']['exp_name'] == 'row_classification':\n",
        "            self.model = BertForSequenceClassification.from_pretrained(\n",
        "                \"bert-base-cased\", \n",
        "                num_labels = self.config['train']['num_classes'], \n",
        "                output_attentions = False, \n",
        "                output_hidden_states = False)\n",
        "        else:\n",
        "            self.model = BertForTokenClassification.from_pretrained(\n",
        "                \"bert-base-cased\", \n",
        "                num_labels = self.config['train']['num_classes'], \n",
        "                output_attentions = False, \n",
        "                output_hidden_states = False)\n",
        "\n",
        "        opt_config = self.config['train']['optim']['AdamW']\n",
        "\n",
        "        for key, val in opt_config.items():\n",
        "\n",
        "            mlflow.log_param(key, val)\n",
        "        mlflow.log_param('nrof_classes', self.config['train']['num_classes'])\n",
        "\n",
        "        self.total_steps = self.config['train']['nrof_steps']\n",
        "        self.optimizer = AdamW(self.model.parameters(),\n",
        "                  lr = opt_config['lr'], \n",
        "                  eps = opt_config['eps'], \n",
        "                  weight_decay=opt_config['weight_decay'])        \n",
        "        self.scheduler = get_cosine_schedule_with_warmup(self.optimizer, \n",
        "                                            num_warmup_steps = 10, \n",
        "                                            num_training_steps = self.total_steps)\n",
        "        self.model.to(self.config['train']['device'])\n",
        "        self.training_stats = []\n",
        "        self.global_step = 0\n",
        "        mlflow.log_param('total_steps', self.total_steps)\n",
        "    \n",
        "    def save_model(self):\n",
        "        torch.save({\"model\": self.model.state_dict(),\n",
        "                    \"optimizer\": self.optimizer.state_dict(),\n",
        "                    \"scheduler\": self.scheduler.state_dict(),\n",
        "                    },\n",
        "                   os.path.join(self.config['paths']['ckpt_dir'], \n",
        "                                self.config['train']['exp_name'] + '_checkpoint'))\n",
        "    \n",
        "    def load_model(self):\n",
        "        ckpt = torch.load(os.path.join(self.config['paths']['ckpt_dir'],\n",
        "                                       self.config['train']['exp_name'] + '_checkpoint'),\n",
        "                          map_location=self.config['train']['device'])\n",
        "        self.global_step = ckpt[\"step\"] + 1\n",
        "        model_st_dict = ckpt[\"model\"]\n",
        "        self.model.load_state_dict(model_st_dict)   \n",
        "        self.optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "        self.scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
        "        print(\"Model loaded...\")\n",
        "\n",
        "\n",
        "    def train(self, train_dataloader, validation_dataloader, to_save=True):\n",
        "        t0 = time()\n",
        "        tr_losses, val_losses = [], []\n",
        "        cur_loss, nrof_steps, nrof_samples, nrof_cor_predicts = 0., 0, 0, 0\n",
        "        if self.config['train']['exp_name'] == 'token_classification':\n",
        "            nrof_rows_cor_predicts, nrof_row_samples = 0,0\n",
        "    \n",
        "        while self.global_step < self.total_steps:\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                self.model.train()\n",
        "                b_input_ids = batch[0].to(self.config['train']['device'])\n",
        "                b_labels = batch[1].to(self.config['train']['device'])\n",
        "                 \n",
        "                self.model.zero_grad()  \n",
        "                outputs = self.model(b_input_ids,\n",
        "                        token_type_ids=None, \n",
        "                    labels=b_labels,\n",
        "                    return_dict=True)  \n",
        "                \n",
        "                cur_loss += outputs.loss.item()\n",
        "                _, predicted = torch.max(outputs.logits,-1)\n",
        "                c = (predicted == b_labels)\n",
        "                nrof_cor_predicts += c.sum().item()\n",
        "                \n",
        "                outputs.loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "                self.optimizer.step()\n",
        "                self.scheduler.step()\n",
        "                self.global_step+=1\n",
        "                nrof_steps+=1\n",
        "                nrof_samples+=len(b_labels)\n",
        "\n",
        "                \n",
        "                if self.global_step % 10 == 0:\n",
        "                    elapsed = format_time(time() - t0)\n",
        "                    print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(self.global_step, len(train_dataloader), elapsed))\n",
        "                    val_acc,  val_loss =\\\n",
        "                     self.validate(validation_dataloader)\n",
        "                    \n",
        "                    print('val loss:', val_loss)\n",
        "                    mlflow.log_metric(\"val_loss\", val_loss)\n",
        "                    mlflow.log_metric(\"val_accuracy\", val_acc)            \n",
        "                    mlflow.log_metric(\"train_loss\", cur_loss / nrof_steps)\n",
        "                    mlflow.log_metric(\"train_accuracy\", float(nrof_cor_predicts)/nrof_samples)\n",
        "                    print('tr loss: {}\\n'.format(cur_loss/nrof_steps))\n",
        "\n",
        "                    cur_loss, nrof_steps = 0., 0\n",
        "                    nrof_cor_predicts, nrof_samples =0,0\n",
        "            training_time = (time() - t0)\n",
        "        \n",
        "        if to_save:\n",
        "            self.save_model()\n",
        "\n",
        "    def validate(self, validation_dataloader, \n",
        "                 to_calc_conf_matr=False, to_load=False):\n",
        "        if to_load:\n",
        "            self.load_model()\n",
        "        t1 = time()\n",
        "        self.model.eval()\n",
        "        val_loss, nrof_cor_predicts, nrof_samples = 0., 0, 0\n",
        "\n",
        "        if to_calc_conf_matr:\n",
        "            conf_matr = np.zeros((self.config['train']['num_classes'],\n",
        "                                  self.config['train']['num_classes']))\n",
        "\n",
        "        for batch in validation_dataloader:\n",
        "            with torch.no_grad(): \n",
        "                b_input_ids = batch[0].to(self.config['train']['device'])\n",
        "                b_labels = batch[1].to(self.config['train']['device'])\n",
        "                outputs = self.model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            labels=b_labels,\n",
        "                            return_dict=True)\n",
        "                val_loss += outputs.loss.item()\n",
        "                _, predicted = torch.max(outputs.logits,-1)\n",
        "                nrof_cor_predicts += (predicted == b_labels).sum().item()\n",
        "\n",
        "                if to_calc_conf_matr:\n",
        "                    if self.config['train']['exp_name'] == 'row_classification':\n",
        "                        np.add.at(conf_matr, [b_labels.cpu().detach().numpy(),\n",
        "                                          predicted.cpu().detach().numpy()],\n",
        "                              [1] * len(b_labels))\n",
        "                    else:\n",
        "                        np.add.at(conf_matr, [b_labels.cpu().detach().numpy().flatten(),\n",
        "                                          predicted.cpu().detach().numpy().flatten()],\n",
        "                              [1] * len(b_labels.cpu().detach().numpy().flatten()))\n",
        "\n",
        "                nrof_samples += len(b_labels)\n",
        "                \n",
        "        avg_val_accuracy = nrof_cor_predicts / nrof_samples\n",
        "        avg_val_loss = val_loss / len(validation_dataloader)\n",
        "        validation_time = (time() - t1)\n",
        "        \n",
        "        if to_calc_conf_matr:\n",
        "            plot_conf_matr(conf_matr)\n",
        "        \n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "        \n",
        "        return avg_val_accuracy, avg_val_loss\n",
        "\n",
        "    def evaluate(self, row, to_load=False):\n",
        "        if to_load:\n",
        "            self.load_model()\n",
        "        self.model.eval()\n",
        "        \n",
        "        outputs = self.model(input_ids.to(self.config['train']['device']), \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=input_mask.to(self.config['train']['device']),\n",
        "                            labels=torch.tensor(1, device=self.config['train']['device']),\n",
        "                            return_dict=True)\n",
        "        pr_class = self.config['train']['class_to_heading_map'][int(torch.max(outputs.logits,1)[1][0])]\n",
        "        \n",
        "        return pr_class \n",
        "\n",
        "    def evaluate_rows(self, rows, inputs, labels):\n",
        "        labeled_text = ''\n",
        "        with torch.no_grad(): \n",
        "            for i, (row, input, label) in enumerate(zip(rows, inputs, labels)):\n",
        "                try:\n",
        "                    outputs = self.model(input.unsqueeze(0).to(self.config['train']['device']),\n",
        "                                token_type_ids=None, \n",
        "                            labels=label.unsqueeze(0).to(self.config['train']['device']),\n",
        "                            return_dict=True)  \n",
        "                    prediction = torch.max(outputs.logits,-1)[1]\n",
        "                    pr_class = self.config['train']['class_to_heading_map'][int(prediction[0])]\n",
        "                    labeled_text+= '\\033[1m' + pr_class+': \\033[0m'+row +'\\n'\n",
        "                except Exception as e:\n",
        "                    print(e)\n",
        "                    continue\n",
        "\n",
        "        return labeled_text\n",
        "\n",
        "    def evaluate_chunks(self, inputs, labels):\n",
        "        labeled_text = ''\n",
        "        with torch.no_grad(): \n",
        "            for input, label in zip(inputs, labels):\n",
        "                text = tokenizer.convert_ids_to_tokens(input)\n",
        "                outputs = self.model(input.unsqueeze(0).to(self.config['train']['device']),\n",
        "                            token_type_ids=None, \n",
        "                        labels=label.unsqueeze(0).to(self.config['train']['device']),\n",
        "                        return_dict=True)  \n",
        "                prediction = torch.max(outputs.logits,-1)[1][0]\n",
        "                current_text, current_label =[], []\n",
        "\n",
        "                for token, label in zip(text[1:], list(prediction)[1:]):\n",
        "                    if not token=='[CLS]':\n",
        "                        current_text.append(token)\n",
        "                        current_label.append(label)\n",
        "                    else:\n",
        "                        current_text = tokenizer.convert_tokens_to_string(current_text)\n",
        "                        row_label = max(set(current_label), key = current_label.count) \n",
        "                        current_text = current_text.replace('[SEP]','')\n",
        "                        labeled_text+= '\\033[1m' + self.config['train']['class_to_heading_map'][row_label.item()]+': \\033[0m'+current_text +'\\n'\n",
        "                        current_text, current_label =[], []\n",
        "\n",
        "        return labeled_text\n",
        "\n",
        "    def evaluate_text(self, text, to_load=False, to_save_text=False, script_name=''):\n",
        "        if to_load:\n",
        "            self.load_model()\n",
        "        self.model.eval()\n",
        "        \n",
        "        text = re.sub('\\n+', '\\n', text)\n",
        "        text = re.sub(' +', ' ', text)\n",
        "        rows = text.split('\\n')\n",
        "        rows = [x.strip() for x in rows]\n",
        "        labels = [0] * len(rows)\n",
        "        labeled_text = ''\n",
        "        if self.config['train']['exp_name'] == 'row_classification':\n",
        "            inputs = make_tokenized_rows(rows, tokenizer)\n",
        "        else:\n",
        "            inputs, labels = make_tokenized_chunks_labels_from_rows(\n",
        "                rows, labels, tokenizer)\n",
        "        inputs, labels = prepare_inputs_labels(inputs, labels)\n",
        "\n",
        "        if self.config['train']['exp_name'] == 'row_classification':\n",
        "            labeled_text = self.evaluate_rows(rows ,inputs, labels)\n",
        "        else:\n",
        "            labeled_text = self.evaluate_chunks(rows, inputs, labels)\n",
        "\n",
        "        if to_save_text:\n",
        "                with open(os.path.join(self.config['paths']['model_annotations'], \n",
        "                                    self.config['train']['exp_name'],\n",
        "                                    script_name +'_anno.txt'), 'w') as f:\n",
        "                    f.write(re.sub('(\\033\\[1m)|(\\033\\[0m)', '', labeled_text))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYbCJ4nCckEI"
      },
      "source": [
        "## Train logging:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkJ8Q0TrSnDF"
      },
      "source": [
        "def log_test_info(tst_acc,  tst_classes_accs, tst_loss):\n",
        "    test_results_txt = 'Test loss: {:3f}\\nTest accuracy: {:3f}\\n'\n",
        "    test_results_txt.format()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZTCWihEY_Sr"
      },
      "source": [
        "T = Train(config)\n",
        "tr_loader, val_loader, tst_loader = get_data_loaders()\n",
        "T.train(tr_loader, val_loader, to_save=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFj-AnHFtO6v"
      },
      "source": [
        "with mlflow.start_run(run_name=config['train']['exp_name']):\n",
        "    tr_loader, val_loader, tst_loader = get_data_loaders()\n",
        "    T = Train(config)\n",
        "    T.train(tr_loader, val_loader)\n",
        "    tst_acc,  tst_loss = T.validate(tst_loader, to_calc_conf_matr=True)\n",
        "    mlflow.log_artifact('conf_matrix.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AtUzfUaVt4K"
      },
      "source": [
        "mlflow.end_run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p78gIOoX9Ji"
      },
      "source": [
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")\n",
        "NGROK_AUTH_TOKEN = \"\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogc1CBCoQkRF"
      },
      "source": [
        "ngrok.kill()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0W7-QL1Fuye"
      },
      "source": [
        "## Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdZn-GRyZ5kC"
      },
      "source": [
        "scripts_path = '/content/drive/MyDrive/NLP/Movie scripts dataset/Movie scripts and annotations/Scripts'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRb01Oh6dn2Y"
      },
      "source": [
        "mean_matching_scores_df = pd.read_excel('/content/drive/MyDrive/NLP/Movie scripts dataset/Movie characters/Matching evaluation and statistics/movies_mean_matching_scores.xlsx')\n",
        "imdb_ids = mean_matching_scores_df[mean_matching_scores_df.iou_values_mean<1.]['imdb_id'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN0bpxbZYGFC"
      },
      "source": [
        "def make_script_annotations(imdb_ids_to_annotate):\n",
        "    T = Train(config)\n",
        "\n",
        "    for id_ in tqdm(imdb_ids_to_annotate):\n",
        "        try:\n",
        "            file_name = [name for name in file_names if str(id_) in name][0]\n",
        "        except:\n",
        "            continue\n",
        "        if not os.path.exists(os.path.join(T.config['paths']['model_annotations'], \n",
        "                                   T.config['train']['exp_name'],\n",
        "                                   file_name.split('.')[0] +'_anno.txt')):\n",
        "            try:\n",
        "                with open(os.path.join(scripts_path, file_name), 'r') as f:\n",
        "                    text = f.read()\n",
        "            except:\n",
        "                try:\n",
        "                    with open(os.path.join(scripts_path, file_name), 'r', encoding='latin-1') as f:\n",
        "                        text = f.read()\n",
        "                except:\n",
        "                    continue\n",
        "            T.evaluate_text(text, to_save_text=True, to_load=True, script_name=file_name.split('.')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0NH511NopE9"
      },
      "source": [
        "make_script_annotations(imdb_ids_to_annotate)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}